{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shortest path relation extraction with word embeddings\n",
    "Approach:\n",
    "* Locate Named Entities in the sentece\n",
    "* Extract dependency path of the sentence using the spaCy dependy parser\n",
    "* Build an undirected network graph of the dependencies in the sentece\n",
    "* Search for the shortest path between every two entities and assume them as related to be each other\n",
    "* Computer feature vector (word embedding) for shortest path feature\n",
    "* Cluster the entities depending on features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "import networkx as nx\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from networkx.exception import NodeNotFound, NetworkXNoPath\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "nlp = spacy.load('de')\n",
    "model = KeyedVectors.load_word2vec_format('../models/german.model', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "relationship_list = ['vater', 'mutter', 'sohn', 'tochter', 'bruder', 'schwester', 'enkel', 'enkelin', 'nichte',\n",
    "                     'neffe', 'onkel', 'tante']\n",
    "me_list = ['ich', 'meine', 'mein', 'meiner', 'meinem', 'meinen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = u'''Herbert ist der Vater von Hans'''\n",
    "#text = u'''Peter und Maria gehen morgen ins Kino'''\n",
    "#text = u'''Herbert sein Sohn und ich gehen heute ins Kino'''\n",
    "# text = u'''Ich gehe mit Johann in den Zoo'''\n",
    "#text = u'''Hans und sein Sohn Hubert gehen in den Zoo.'''\n",
    "#text = u'''Hans, welcher der Sohn von Hubert ist, geht mit Peter ins Kino.'''\n",
    "text = u'''Meine kleine Enkelin Lisa und mein Enkel Lukas fliegen morgen nach London.'''\n",
    "#text = u'''Ich fahre mit meinen Enkeln Lukas und Lisa in den Urlaub.'''\n",
    "#text = u'''Potesters seized several pumping stations, holding 127 Shell workers hostage.'''\n",
    "#text = u'''Troops recently have raided churches, warning ministers to stop preaching.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spaCy NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lisa', 'lukas', 'meine', 'mein']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities = []\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == 'PER':\n",
    "        entities.append(ent.text.lower())\n",
    "\n",
    "for token in doc:\n",
    "    if token.text.lower() in me_list:\n",
    "        entities.append(token.text.lower())\n",
    "\n",
    "entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flair NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER-span [1]: \"Hans,\"\n",
      "PER-span [3,4,5,6]: \"der Sohn von Hubert\"\n",
      "PER-span [10]: \"Peter\"\n",
      "Token: 1 Hans,, S-PER (0.9007681608200073)\n",
      "Token: 2 welcher, O (0.9998061060905457)\n",
      "Token: 3 der, B-PER (0.5459927916526794)\n",
      "Token: 4 Sohn, I-PER (0.7497949600219727)\n",
      "Token: 5 von, I-PER (0.9713440537452698)\n",
      "Token: 6 Hubert, E-PER (0.9999539852142334)\n",
      "Token: 7 ist,, O (1.0)\n",
      "Token: 8 geht, O (1.0)\n",
      "Token: 9 mit, O (0.9999814033508301)\n",
      "Token: 10 Peter, S-PER (0.9990077614784241)\n",
      "Token: 11 ins, O (0.9999983310699463)\n",
      "Token: 12 Kino., O (0.9989665746688843)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Hans,', 'der Sohn von Hubert', 'Peter']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "flair_entities = []\n",
    "\n",
    "sentence = Sentence(text)\n",
    "tagger = SequenceTagger.load('ner')\n",
    "tagger.predict(sentence) # run NER over sentence\n",
    "\n",
    "for entity in sentence.get_spans('ner'):\n",
    "    print(entity)\n",
    "    if entity.tag == 'PER':\n",
    "        flair_entities.append(entity.text)\n",
    "\n",
    "for token in sentence:\n",
    "    ner_tag = token.get_tag('ner')\n",
    "    print(f'{token}, {ner_tag}')\n",
    "        \n",
    "flair_entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build undirected graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in sent_tokenize(text):\n",
    "    doc = nlp(sentence)\n",
    "    edges = []\n",
    "    for token in doc:\n",
    "        for child in token.children:\n",
    "            edges.append((f'{token.lower_}',\n",
    "                          f'{child.lower_}'))\n",
    "\n",
    "    graph = nx.Graph(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python\\lib\\site-packages\\networkx\\drawing\\nx_pylab.py:611: MatplotlibDeprecationWarning: isinstance(..., numbers.Number)\n",
      "  if cb.is_numlike(alpha):\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# nx.draw_networkx(graph, node_size=100, ode_color=range(len(graph)))\n",
    "pos = nx.spring_layout(graph)  # positions for all nodes\n",
    "# nodes\n",
    "nx.draw_networkx_nodes(graph, pos, node_size=200)\n",
    "# edges\n",
    "nx.draw_networkx_edges(graph, pos, width=1)\n",
    "# labels\n",
    "nx.draw_networkx_labels(graph, pos, font_size=12, font_family='sans-serif')\n",
    "\n",
    "plt.axis('off')  # disable axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shortest Path\n",
    "Find shortest path between every found two entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lisa-lukas': ['lisa', 'und', 'enkel', 'lukas']}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dict = {}\n",
    "for i, first_entity in enumerate(entities):\n",
    "    for j in range(i+1, len(entities)):\n",
    "        second_entity = entities[j]\n",
    "        if not i == j and second_entity not in me_list:        \n",
    "            try:\n",
    "                shortest_path = nx.shortest_path(graph, source=first_entity, target=second_entity)\n",
    "                key = first_entity + '-' + second_entity\n",
    "                path_dict[key] = shortest_path\n",
    "            except NodeNotFound as err:\n",
    "                logging.warning(f'Node not found: {err}')\n",
    "            except NetworkXNoPath as err:\n",
    "                logging.warning(f'No path found: {err}')\n",
    "\n",
    "path_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['m1', 'm2', 'm1_pos', 'm2_pos', 'before_m1', 'after_m2', 'between_words', \n",
    "                   'short_path', 'm1_head', 'm2_head']\n",
    "\n",
    "features = pd.DataFrame(columns=feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = []  # for TF-IDF vectorization\n",
    "#ners = []\n",
    "\n",
    "# check for named entity 'PER' or 'PME' in each sentence\n",
    "#for ner_tuple in ner_tuples:\n",
    "#    if 'I-PER' in ner_tuple:\n",
    "#        ners.append(ner_tuple)\n",
    "#    elif ner_tuple[0].lower() in me_list:\n",
    "#        ners.append((ner_tuple[0], 'PME'))\n",
    "#    elif ner_tuple[0].lower() in relationship_list:\n",
    "#        ners.append((ner_tuple[0], 'SOC'))\n",
    "\n",
    "for sentence in sent_tokenize(text):\n",
    "    sentence = re.sub(r'\\W', ' ', sentence)\n",
    "    sentence = re.sub(r'\\s{2,}', ' ', sentence)\n",
    "    sentence = sentence.lower()\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    for key, value in path_dict.items():\n",
    "        # extract entities\n",
    "        m1 = key.split('-')[0]\n",
    "        m2 = key.split('-')[1]\n",
    "\n",
    "        short_path = value\n",
    "\n",
    "        # POS tagging and head\n",
    "        for token in doc:\n",
    "            if token.text.lower() == m1:\n",
    "                m1_pos_tag = token.pos_\n",
    "                m1_head = token.head.text\n",
    "                #m1_children = [child for child in token.children]\n",
    "            elif token.text.lower() == m2:\n",
    "                m2_pos_tag = token.pos_\n",
    "                m2_head = token.head.text\n",
    "                #m2_children = [child for child in token.children]\n",
    "\n",
    "        # Dependecy parsing\n",
    "        #dep_path = []\n",
    "        #for chunk in doc.noun_chunks:\n",
    "        #    if chunk.root.text.lower() == m1 or chunk.root.text.lower() == m2:\n",
    "        #        dep_path.append([chunk.root.text, chunk.root.dep_, chunk.root.head.text])  \n",
    "\n",
    "        # Between words\n",
    "        start_position_m1 = sentence.find(m1)\n",
    "        start_position_m2 = sentence.find(m2)\n",
    "\n",
    "        # verify if the words were found in the sentence\n",
    "        if not start_position_m1 == -1 and not start_position_m2 == -1:\n",
    "            start_position_between = start_position_m1 + len(m1) + 1\n",
    "            end_position_between = start_position_m2\n",
    "\n",
    "            between = sentence[start_position_between:end_position_between]\n",
    "            between_words = []\n",
    "            for word in word_tokenize(between):\n",
    "                between_words.append(word)\n",
    "\n",
    "            beforeM1 = sentence[:start_position_m1 - 1]\n",
    "            afterM2 = sentence[start_position_m2 + len(m2):]\n",
    "\n",
    "            beforeM1_list = word_tokenize(beforeM1)\n",
    "            afterM2_list = word_tokenize(afterM2)\n",
    "\n",
    "            data = {'m1': m1, 'm2': m2, 'm1_pos': m1_pos_tag, 'm2_pos': m2_pos_tag,\n",
    "                    'before_m1': beforeM1_list, 'after_m2': afterM2_list,\n",
    "                    'between_words': between_words, 'short_path': short_path,\n",
    "                     'm1_head': m1_head, 'm2_head': m2_head}\n",
    "\n",
    "            training_example = pd.Series(data, index=feature_columns)\n",
    "            features = features.append(training_example, ignore_index=True)\n",
    "            #context = [beforeM1, between, afterM2]\n",
    "            #features_list.append(context)\n",
    "\n",
    "#features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m1</th>\n",
       "      <th>m2</th>\n",
       "      <th>m1_pos</th>\n",
       "      <th>m2_pos</th>\n",
       "      <th>before_m1</th>\n",
       "      <th>after_m2</th>\n",
       "      <th>between_words</th>\n",
       "      <th>short_path</th>\n",
       "      <th>m1_head</th>\n",
       "      <th>m2_head</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lisa</td>\n",
       "      <td>lukas</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>[meine, kleine, enkelin]</td>\n",
       "      <td>[fliegen, morgen, nach, london]</td>\n",
       "      <td>[und, mein, enkel]</td>\n",
       "      <td>[lisa, und, enkel, lukas]</td>\n",
       "      <td>kleine</td>\n",
       "      <td>und</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     m1     m2 m1_pos m2_pos                 before_m1  \\\n",
       "0  lisa  lukas      X      X  [meine, kleine, enkelin]   \n",
       "\n",
       "                          after_m2       between_words  \\\n",
       "0  [fliegen, morgen, nach, london]  [und, mein, enkel]   \n",
       "\n",
       "                  short_path m1_head m2_head  \n",
       "0  [lisa, und, enkel, lukas]  kleine     und  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vector_feature_columns = ['m1', 'm2', 'short_path_vector']\n",
    "vector_features = pd.DataFrame(columns=vector_feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Word Embeddings of the words inside the shortest path and sum them into a single vector\n",
    "* Two Representations: GermanWordEmbeddings and Flair Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GermanWordEmbeddings https://github.com/devmount/GermanWordEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\program files\\python\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"word 'lisa' not in vocabulary\"\n",
      "\"word 'und' not in vocabulary\"\n",
      "\"word 'enkel' not in vocabulary\"\n",
      "\"word 'lukas' not in vocabulary\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m1</th>\n",
       "      <th>m2</th>\n",
       "      <th>short_path_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lisa</td>\n",
       "      <td>lukas</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     m1     m2 short_path_vector\n",
       "0  lisa  lukas               NaN"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_vectors = []\n",
    "# get vector length\n",
    "vector_len = len(model.wv['hallo'])\n",
    "\n",
    "for row in features.iterrows():\n",
    "    m1 = row[1]['m1']\n",
    "    m2 = row[1]['m2']\n",
    "    short_path = row[1]['short_path']\n",
    "    \n",
    "    # get the word embedding representation for each word in the shortest path\n",
    "    #row_embeddings = np.empty(len(short_path))\n",
    "    row_embeddings = []\n",
    "    \n",
    "    for word in short_path:\n",
    "        try:\n",
    "            row_embeddings.append(model.wv[word])\n",
    "        except KeyError as err:\n",
    "            print(err)\n",
    "            row_embeddings.append(np.zeros(vector_len))\n",
    "    \n",
    "    #print(sum(row_embeddings))\n",
    "    embedding_vectors.append(sum(row_embeddings))\n",
    "    vector_data = {'m1': m1, 'm2': m2, 'short_path_embedding_vector': sum(row_embeddings)}\n",
    "    training_example = pd.Series(vector_data, index=vector_feature_columns)\n",
    "    vector_features = vector_features.append(training_example, ignore_index=True)\n",
    "\n",
    "# summarize vectors    \n",
    "#row_embeddings.sum()\n",
    "vector_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flair Word Embeddings  https://github.com/zalandoresearch/flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meine': tensor([ 0.3143,  0.3278,  0.2227, -0.1677,  0.5473,  0.2437, -0.3142,  0.3915,\n",
       "          0.3547,  0.5824,  0.1649,  0.3327,  0.3768, -0.4037,  0.0269,  0.1569,\n",
       "          0.0401, -0.0803, -0.2197, -0.0987,  0.4248,  0.2022, -0.0841,  0.1526,\n",
       "         -0.0641, -0.2699,  0.0332,  0.1664, -0.2501, -0.1808,  0.1072,  0.2039,\n",
       "          0.2110,  0.1317, -0.2445,  0.0427,  0.0964,  0.0453, -0.0670, -0.0518,\n",
       "          0.1498, -0.0018, -0.1923,  0.2518,  0.1408, -0.1361, -0.0740,  0.0485,\n",
       "         -0.2115, -0.1467, -0.1199,  0.2396, -0.1005,  0.3569,  0.2009, -0.3709,\n",
       "         -0.0636,  0.0463, -0.3676, -0.0399, -0.0479,  0.0361,  0.3456, -0.4005,\n",
       "         -0.0258, -0.2524, -0.0583, -0.1448, -0.1527,  0.0059,  0.1928, -0.1826,\n",
       "          0.0233,  0.2726, -0.5819, -0.0681,  0.2317,  0.1351, -0.1200, -0.2610,\n",
       "         -0.2752,  0.0340,  0.0070, -0.2621, -0.1474, -0.3576, -0.2069,  0.1816,\n",
       "         -0.1402,  0.2674,  0.1013, -0.4401,  0.1934, -0.1284, -0.1108, -0.2443,\n",
       "          0.1305,  0.3917, -0.2231, -0.0789,  0.3672,  0.4745,  0.2152, -0.0438,\n",
       "         -0.0931, -0.2166,  0.3645, -0.1496, -0.0128,  0.4056,  0.5002,  0.0467,\n",
       "          0.2448, -0.0462,  0.2555,  0.2679, -0.1740,  0.1586, -0.1898,  0.1553,\n",
       "         -0.1237,  0.1280, -0.0982,  0.3461,  0.0210,  0.3065, -0.0341,  0.0104,\n",
       "         -0.0122, -0.2309,  0.2108, -0.1193, -0.1187,  0.1001, -0.0244,  0.1979,\n",
       "          0.0452, -0.1920,  0.1097, -0.1359, -0.0491, -0.0689, -0.1709,  0.2944,\n",
       "          0.2223, -0.1208,  0.0047,  0.2748, -0.2079,  0.0010,  0.5639,  0.2103,\n",
       "         -0.2040,  0.1649, -0.0611, -0.0633, -0.5184,  0.2084,  0.2357,  0.2719,\n",
       "         -0.0478,  0.2390, -0.0697,  0.3154,  0.0973,  0.6384, -0.6115, -0.0699,\n",
       "         -0.2059,  0.4360,  0.0901, -0.1163,  0.1651, -0.1924, -0.0311, -0.0220,\n",
       "         -0.2740, -0.1427,  0.1327, -0.4290,  0.1148,  0.4173, -0.1095, -0.1510,\n",
       "         -0.0193,  0.6271, -0.1681, -0.1579, -0.3315,  0.1395, -0.1157,  0.2959,\n",
       "          0.0774,  0.2135, -0.3783, -0.4085,  0.3054,  0.2880,  0.0189, -0.0764,\n",
       "         -0.0401,  0.0606, -0.1790, -0.0028, -0.1457,  0.0920, -0.2510, -0.3128,\n",
       "         -0.5483,  0.3015,  0.4937, -0.0882,  0.4000,  0.0056, -0.3619,  0.0605,\n",
       "         -0.1664,  0.0533, -0.1276,  0.1651,  0.1401, -0.1300,  0.2631,  0.1010,\n",
       "         -0.1509,  0.4525, -0.0141,  0.3256, -0.0697,  0.0676, -0.2492,  0.0531,\n",
       "         -0.0650, -0.4408,  0.1247, -0.6285, -0.2212, -0.0374,  0.0160, -0.0136,\n",
       "         -0.1746,  0.0777, -0.0372, -0.0405,  0.2691, -0.1526, -0.1173,  0.0590,\n",
       "          0.0059,  0.1129,  0.0795,  0.0235, -0.3255, -0.0044, -0.2414,  0.0461,\n",
       "          0.0339, -0.3304, -0.2862,  0.4536,  0.4078,  0.1010,  0.1847,  0.3015,\n",
       "         -0.2362,  0.0401, -0.3354, -0.1012, -0.1901,  0.0855,  0.0337,  0.0140,\n",
       "          0.1915,  0.2731,  0.3760, -0.0187,  0.0514, -0.0687, -0.0232,  0.3771,\n",
       "         -0.1101,  0.2211,  0.0320, -0.0121,  0.2758,  0.0386,  0.0638, -0.0507,\n",
       "          0.1091,  0.4396, -0.2159,  0.2585, -0.0279,  0.3369, -0.0851, -0.1894,\n",
       "         -0.0206, -0.0652,  0.1678,  0.2199]),\n",
       " 'kleine': tensor([-0.1755,  0.2906,  0.1238,  0.1394, -0.1232, -0.0056, -0.1889, -0.0313,\n",
       "          0.2486,  0.2038, -0.1063,  0.0565,  0.5473,  0.0998, -0.3004,  0.4161,\n",
       "         -0.0877, -0.1548, -0.0802, -0.0250,  0.1583,  0.0468,  0.3984, -0.1598,\n",
       "         -0.0477, -0.0526, -0.1089,  0.0691, -0.3942,  0.0853, -0.0078,  0.3566,\n",
       "         -0.2622,  0.0805,  0.2198, -0.1623, -0.1474,  0.2891, -0.0567, -0.1474,\n",
       "          0.2305, -0.4271,  0.1096,  0.4112, -0.0521, -0.1501,  0.0095,  0.1762,\n",
       "          0.0961,  0.0596,  0.2543,  0.2885, -0.5221,  0.0740,  0.3514,  0.2759,\n",
       "         -0.5459, -0.0879, -0.2678, -0.0899,  0.0437,  0.2167,  0.4712, -0.0852,\n",
       "          0.1637, -0.1652, -0.1419, -0.2070,  0.1227, -0.0335, -0.0269, -0.1688,\n",
       "          0.1457,  0.2256, -0.2309, -0.1381,  0.4101,  0.1293, -0.0024,  0.3182,\n",
       "         -0.0104,  0.1497, -0.1262,  0.0147,  0.1853, -0.1049,  0.0750,  0.0526,\n",
       "         -0.3480,  0.1075,  0.0019,  0.0444, -0.2715, -0.0639,  0.1644, -0.1191,\n",
       "         -0.5808,  0.1828, -0.3907,  0.1156, -0.2721,  0.4108,  0.1013,  0.1961,\n",
       "          0.0737,  0.1222, -0.2389, -0.2510, -0.4128,  0.0752,  0.2728,  0.3336,\n",
       "          0.0516, -0.0104,  0.0511,  0.4191,  0.2770, -0.1135, -0.1618,  0.0683,\n",
       "         -0.0152, -0.2103,  0.4936, -0.2976,  0.0848,  0.1725,  0.0336, -0.0102,\n",
       "          0.1189, -0.0246, -0.2865, -0.3618,  0.2189,  0.4393,  0.2852,  0.1167,\n",
       "         -0.0819,  0.3042,  0.7320, -0.2275,  0.0393, -0.2757,  0.1576, -0.0666,\n",
       "         -0.1064,  0.0527, -0.1720, -0.1075,  0.1420,  0.0509,  0.2325, -0.2511,\n",
       "         -0.0977, -0.0108, -0.0175, -0.1194, -0.2978, -0.0336, -0.0545,  0.0136,\n",
       "          0.2891,  0.3015,  0.0042,  0.3318,  0.4239,  0.1310, -0.2452,  0.0488,\n",
       "          0.0179,  0.6476, -0.5343, -0.2405,  0.0482, -0.0570,  0.0686, -0.1606,\n",
       "         -0.2794, -0.1239,  0.1403,  0.1543,  0.0272,  0.2334, -0.3256, -0.0094,\n",
       "          0.0604,  0.3213,  0.1355, -0.1572, -0.0393,  0.3426, -0.0482, -0.2130,\n",
       "         -0.0801, -0.1317, -0.2492, -0.6426,  0.1830,  0.1375, -0.4086, -0.0672,\n",
       "          0.0297, -0.3578, -0.3037,  0.0387, -0.1454,  0.2775,  0.2307, -0.2540,\n",
       "          0.2676, -0.1436,  0.0330, -0.1157, -0.1663,  0.0354, -0.1224, -0.0219,\n",
       "          0.0326,  0.0260, -0.1146,  0.1797, -0.1296, -0.2733,  0.0394, -0.2335,\n",
       "         -0.1702, -0.1800,  0.3619,  0.2204, -0.2817, -0.0802,  0.1729, -0.2107,\n",
       "         -0.1976, -0.0551, -0.0675, -0.0983, -0.1709, -0.0117,  0.1662, -0.1864,\n",
       "          0.1836, -0.0779, -0.1068, -0.1840, -0.2064, -0.0193,  0.2016,  0.1240,\n",
       "          0.2494,  0.2138, -0.3947,  0.0763, -0.0107, -0.1193,  0.2146, -0.2654,\n",
       "         -0.0808,  0.0651, -0.2950, -0.2280,  0.2999, -0.4904,  0.0832,  0.0210,\n",
       "         -0.2641, -0.0159,  0.0032,  0.0650, -0.3364, -0.4329,  0.1282, -0.1935,\n",
       "          0.5577, -0.3304,  0.4029,  0.2024, -0.2229,  0.0661, -0.0769,  0.3670,\n",
       "         -0.0567,  0.1771, -0.0173, -0.0121,  0.2677, -0.4973, -0.0195, -0.0980,\n",
       "         -0.0043, -0.0142, -0.4112,  0.2323, -0.2612,  0.4465, -0.2964, -0.0747,\n",
       "         -0.2743,  0.2805,  0.5803, -0.0343]),\n",
       " 'enkelin': tensor([-1.4185e-01,  4.0902e-01, -5.6860e-01, -3.8065e-01,  2.0821e-01,\n",
       "          2.2227e-01, -2.2693e-01, -1.4222e-01, -2.5761e-02,  5.8720e-01,\n",
       "          5.9643e-02,  3.6513e-01, -4.1791e-02, -1.8425e-01,  2.2861e-01,\n",
       "         -1.3136e-01, -3.0480e-01,  5.8865e-01, -4.1735e-01,  2.1678e-01,\n",
       "          2.9310e-01, -1.3817e-01, -1.6421e-01,  8.9941e-01, -5.5000e-02,\n",
       "         -3.1066e-01, -3.5592e-01,  5.5159e-01, -3.9238e-01, -4.2425e-01,\n",
       "          3.6803e-01,  1.3475e-01,  1.7704e-01,  2.6781e-01, -2.4280e-01,\n",
       "         -3.7135e-01, -5.8887e-01, -1.4025e-02, -5.7455e-01,  5.7528e-01,\n",
       "         -4.9325e-02,  7.0572e-02, -3.8802e-02,  8.0057e-02, -1.3770e-01,\n",
       "         -2.7664e-01,  3.0501e-02, -1.2632e-01,  3.6881e-01, -2.1439e-01,\n",
       "         -1.2168e-01, -1.6974e-02,  8.8247e-02, -5.3423e-02,  5.3678e-02,\n",
       "          1.2544e-02, -5.1130e-01, -1.7283e-01, -2.5045e-01, -2.4863e-01,\n",
       "         -3.9984e-01, -3.1731e-01,  2.7900e-02, -3.2444e-01, -1.3473e-01,\n",
       "          2.6864e-01, -4.9260e-01,  2.4924e-02,  5.4826e-02, -2.0984e-02,\n",
       "         -3.0525e-01, -5.2377e-02,  2.3585e-01,  3.3751e-01,  1.3422e-01,\n",
       "          5.6918e-02,  5.2410e-02, -3.5128e-01, -1.9937e-01, -1.3436e-01,\n",
       "          8.1185e-02, -1.1402e-01,  1.5342e-02,  1.6266e-01, -3.1895e-01,\n",
       "         -1.7400e-01, -1.6382e-01,  9.8421e-02, -2.6692e-01, -3.6939e-01,\n",
       "          3.7693e-02, -2.6024e-02, -3.1460e-01, -2.2435e-01,  1.6146e-01,\n",
       "         -3.5521e-01,  1.8296e-01, -2.4046e-04, -2.1887e-01, -1.5726e-01,\n",
       "          2.2141e-01, -3.7990e-02, -1.5053e-01,  5.8498e-02, -3.5344e-01,\n",
       "          1.6464e-01, -2.5523e-01,  4.8494e-01, -1.2159e-01, -8.2203e-02,\n",
       "         -4.0767e-01, -1.3832e-03,  3.2608e-01, -4.1058e-01,  4.8911e-02,\n",
       "          2.0470e-01,  2.4739e-01, -1.3896e-01, -2.3659e-02, -4.5444e-01,\n",
       "          2.1063e-01,  4.6422e-01,  3.4934e-01,  2.9030e-01, -1.2500e-01,\n",
       "          2.1439e-01,  4.2177e-01,  6.6468e-02, -3.9141e-01, -4.0958e-01,\n",
       "          2.8774e-01, -3.1000e-03,  3.0231e-01, -7.9923e-02, -1.7101e-01,\n",
       "         -3.0872e-01,  7.5950e-03, -9.4737e-03,  1.7679e-01, -1.0189e-01,\n",
       "         -4.6140e-01, -6.3146e-01,  1.0817e-02,  1.2222e-01,  3.5009e-01,\n",
       "         -4.1638e-01, -5.9672e-02, -1.8209e-02,  2.1996e-01,  2.6990e-01,\n",
       "          1.0104e-01, -3.3169e-01,  1.0964e-01,  1.3468e-01,  4.2401e-01,\n",
       "          5.7912e-02, -1.6561e-01,  3.4756e-02,  3.7387e-01,  1.1484e-01,\n",
       "         -1.8253e-02,  2.4120e-01, -1.3585e-01,  1.0971e-01,  1.0157e-01,\n",
       "         -3.6547e-01, -3.7042e-01,  3.0285e-01, -1.7172e-01,  9.9668e-02,\n",
       "         -4.6664e-01, -2.6504e-01,  2.9945e-01, -4.4848e-02, -4.7934e-02,\n",
       "          4.1851e-01,  1.6730e-01, -3.2973e-02, -5.0132e-01, -6.0739e-01,\n",
       "          1.8866e-01,  1.8568e-01,  3.2935e-02,  9.6741e-02,  1.0848e-01,\n",
       "          1.6484e-01,  5.4889e-02,  1.4165e-01, -3.9625e-01,  2.1227e-01,\n",
       "          3.5765e-01, -4.4441e-01, -1.9522e-01, -3.5626e-01,  4.0629e-01,\n",
       "         -3.6795e-01, -2.0478e-01,  3.4226e-02, -7.2499e-01,  7.5693e-02,\n",
       "         -8.4054e-01, -1.4530e-01,  8.3142e-03,  5.3855e-02,  1.1570e-01,\n",
       "          3.1518e-01, -1.0665e-01, -1.4280e-01, -1.9389e-01,  2.6766e-01,\n",
       "          5.8428e-02, -5.8991e-02,  4.7284e-01, -1.5665e-01, -4.3007e-02,\n",
       "          2.0780e-01, -4.0197e-01,  2.1218e-01, -2.5363e-01, -1.0186e-01,\n",
       "         -1.3330e-01,  2.0219e-01, -2.9356e-01,  2.8816e-01, -5.7706e-01,\n",
       "          1.0785e-01, -2.8980e-02, -2.4575e-02,  3.8517e-01,  9.7720e-02,\n",
       "          9.8156e-03, -1.3344e-01, -1.1423e-01, -2.3119e-01,  9.2648e-02,\n",
       "         -3.4502e-01,  1.4307e-01, -1.2468e-01,  2.3135e-01, -6.3699e-01,\n",
       "          2.1039e-01,  3.0366e-01, -3.5308e-01, -2.0664e-02, -1.2142e-01,\n",
       "          1.2928e-01,  2.0278e-02, -9.2826e-02, -1.7136e-01,  2.0978e-01,\n",
       "          4.1309e-02,  2.0388e-02, -1.5049e-01, -6.4370e-02,  5.1435e-01,\n",
       "         -6.0629e-01,  4.6622e-01, -2.6733e-02, -5.2365e-01,  1.5899e-01,\n",
       "         -6.1860e-02, -2.4075e-01, -5.1635e-01, -4.4387e-03, -2.5198e-01,\n",
       "          4.1301e-02,  1.1220e-01,  1.8700e-01, -7.2737e-03,  1.2411e-02,\n",
       "         -2.5068e-01,  1.0167e-01,  1.5895e-02,  6.9494e-02,  4.3865e-01,\n",
       "         -4.2350e-01,  8.6327e-02, -1.1481e-01, -4.7981e-01,  5.1490e-01,\n",
       "          2.4555e-01,  5.2180e-01, -3.4008e-01,  1.7626e-01,  3.8188e-02,\n",
       "          1.0675e-02, -2.9520e-01,  3.3520e-01, -2.6990e-01,  3.7721e-01,\n",
       "          7.3345e-02, -3.5163e-01,  8.2225e-02,  2.9226e-01, -3.6754e-01,\n",
       "         -5.5955e-01,  1.7925e-02, -2.9231e-01,  1.6248e-01,  3.6587e-01]),\n",
       " 'lisa': tensor([-0.1503,  0.0544, -0.5179, -0.1365, -0.3145,  0.2138, -0.1560,  0.1417,\n",
       "          0.5743,  0.2433, -0.0106, -0.3225,  0.0472, -0.1969,  0.2160,  0.0489,\n",
       "          0.1411,  0.0541,  0.0661,  0.2256,  0.0048,  0.2220,  0.2677,  0.4958,\n",
       "         -0.2894, -0.1005, -0.1159,  0.5286,  0.0415, -0.2998,  0.2598, -0.0637,\n",
       "          0.0375, -0.5919, -0.6229, -0.6496, -0.0418,  0.1927, -0.2373, -0.2811,\n",
       "         -0.1702, -0.1424,  0.0819, -0.0838, -0.2813, -0.1230, -0.0241, -0.5405,\n",
       "         -0.4407, -0.0257,  0.2811,  0.2039,  0.5396, -0.2000, -0.0178, -0.3714,\n",
       "         -0.1045,  0.0015,  0.0256, -0.0989, -0.1062, -0.1519,  0.7059,  0.2547,\n",
       "         -0.1106, -0.0689,  0.1985,  0.3458, -0.1905,  0.3392, -0.2786, -0.1087,\n",
       "         -0.0548,  0.0305, -0.0520, -0.0914, -0.0151, -0.1306, -0.1129,  0.3000,\n",
       "          0.3577, -0.1714, -0.1488,  0.1759, -0.6071,  0.0646,  0.2869,  0.2862,\n",
       "         -0.2259,  0.1117, -0.5096,  0.1578,  0.3676, -0.2478,  0.0994, -0.0941,\n",
       "         -0.1768,  0.5089, -0.4776,  0.2276,  0.3837,  0.1711,  0.2951, -0.4339,\n",
       "          0.4661,  0.0392, -0.1344,  0.3782, -0.0351,  0.3988,  0.1623,  0.3318,\n",
       "          0.2639, -0.0164,  0.3760, -0.2374, -0.5114,  0.0174, -0.4465,  0.0542,\n",
       "          0.1704,  0.0718,  0.3915,  0.4162,  0.3145,  0.2351,  0.3983, -0.0482,\n",
       "         -0.2335,  0.2247, -0.0730,  0.1603,  0.2458,  0.3191,  0.2002, -0.0098,\n",
       "         -0.2633,  0.2301,  0.4810, -0.2114, -0.2442, -0.0523,  0.4977,  0.1883,\n",
       "          0.0819, -0.3309,  0.2670, -0.1296, -0.0316,  0.0554,  0.0422,  0.4309,\n",
       "         -0.1178,  0.5131,  0.3350, -0.0493, -0.3413,  0.5069,  0.4997,  0.2834,\n",
       "          0.1812,  0.1043, -0.5374, -0.1717, -0.0142, -0.1728, -0.1664, -0.1463,\n",
       "         -0.3548, -0.3980, -0.4137,  0.0398, -0.0601, -0.1803, -0.5287,  0.2788,\n",
       "          0.2532, -0.3695, -0.4747, -0.3996, -0.3525, -0.2733, -0.2503, -0.2673,\n",
       "          0.0892,  0.0888,  0.1881,  0.4027,  0.1186,  0.3939,  0.1894, -0.1061,\n",
       "         -0.1524, -0.0631,  0.4080, -0.1611, -0.0864, -0.0164, -0.5980, -0.1089,\n",
       "         -0.0259,  0.0900,  0.1445,  0.0376,  0.0630,  0.2362,  0.1197,  0.0038,\n",
       "         -0.1568, -0.1031, -0.1203, -0.1830,  0.2219, -0.1491, -0.6877,  0.2543,\n",
       "          0.1700,  0.1731, -0.1575, -0.2866, -0.3954, -0.4168, -0.1112,  0.2071,\n",
       "         -0.2836,  0.1198, -0.0295, -0.0254,  0.2648,  0.1834,  0.2524,  0.4051,\n",
       "         -0.0953, -0.0480, -0.0702, -0.6124,  0.1238,  0.2877,  0.1642, -0.3349,\n",
       "          0.0617,  0.3424, -0.1180, -0.0540, -0.2793, -0.0859,  0.1134,  0.4192,\n",
       "          0.2096,  0.4532, -0.0661,  0.1050,  0.0020,  0.0492,  0.1098, -0.6057,\n",
       "         -0.0479, -0.0223, -0.4922,  0.2418,  0.1220,  0.0461,  0.0643,  0.3087,\n",
       "          0.0066,  0.0244, -0.1799,  0.2222, -0.0669, -0.2764, -0.1436,  0.3796,\n",
       "          0.1850,  0.0287,  0.0072, -0.4831,  0.3109, -0.1973, -0.2356,  0.4353,\n",
       "         -0.0854,  0.0685, -0.1377,  0.4377,  0.2400, -0.6302, -0.5393, -0.1832,\n",
       "         -0.5095,  0.3330, -0.0649, -0.4293,  0.1042,  0.4970,  0.0694, -0.1439,\n",
       "         -0.2938, -0.2523, -0.1813,  0.1636]),\n",
       " 'und': tensor([-0.1778, -0.0642, -0.0947, -0.1643, -0.0839,  0.0527, -0.1037,  0.0792,\n",
       "         -0.0489, -0.0030, -0.0516,  0.1631,  0.0122, -0.0683, -0.1193,  0.0614,\n",
       "         -0.0555,  0.0200, -0.1096,  0.0664,  0.1145,  0.0234,  0.0927, -0.0402,\n",
       "         -0.0670, -0.0625,  0.1815,  0.1322, -0.0423, -0.0670,  0.0442,  0.0744,\n",
       "          0.1399,  0.0026,  0.0575,  0.0453, -0.0321, -0.0888, -0.1360,  0.1080,\n",
       "         -0.1230, -0.2637, -0.1742,  0.1480,  0.0351, -0.2172,  0.0488, -0.0689,\n",
       "         -0.0164, -0.1180, -0.0701,  0.0145,  0.1061,  0.1285,  0.0374, -0.0105,\n",
       "          0.0558,  0.0728,  0.0097,  0.1185, -0.0063,  0.0129,  0.1103, -0.0727,\n",
       "         -0.0757, -0.3421, -0.0135,  0.1204, -0.0652, -0.0391, -0.1937, -0.1165,\n",
       "         -0.1613,  0.1325, -0.1559,  0.1086, -0.0972, -0.2219,  0.0548,  0.0742,\n",
       "         -0.1212, -0.0525,  0.2623,  0.0394,  0.2046, -0.0897,  0.0784,  0.1731,\n",
       "         -0.1272, -0.0029,  0.1019,  0.0427, -0.1533, -0.0304, -0.0320, -0.1393,\n",
       "          0.1369,  0.2031, -0.2494,  0.0656,  0.0749,  0.1781, -0.0868,  0.1447,\n",
       "          0.2342,  0.3546, -0.1609,  0.1157, -0.0659, -0.0716, -0.0499,  0.0952,\n",
       "         -0.0211,  0.0518, -0.1245,  0.1446,  0.2587,  0.1504, -0.0263, -0.0151,\n",
       "         -0.0567, -0.0565,  0.2093,  0.1043, -0.1063,  0.0366, -0.0534,  0.0770,\n",
       "          0.0417,  0.0508, -0.2048, -0.1474, -0.0223,  0.0117,  0.1552,  0.0076,\n",
       "         -0.0501, -0.0355,  0.0898, -0.0853, -0.1266,  0.1951, -0.0025,  0.1931,\n",
       "          0.0221,  0.0161,  0.0609,  0.1383,  0.0830,  0.0691,  0.2831, -0.0772,\n",
       "         -0.0752, -0.0239, -0.0345,  0.1030, -0.0128,  0.1251,  0.1880,  0.0360,\n",
       "         -0.0638, -0.0257, -0.1083,  0.1145, -0.0936,  0.1382, -0.1097,  0.0685,\n",
       "         -0.1415,  0.1370, -0.2200, -0.0590,  0.0819,  0.0971, -0.1120, -0.0313,\n",
       "         -0.0331, -0.0026,  0.0711,  0.0532,  0.0008,  0.1231, -0.1220, -0.0548,\n",
       "         -0.0914,  0.0998,  0.1780, -0.1124, -0.1191, -0.0259,  0.0740, -0.0120,\n",
       "          0.1205,  0.2365,  0.0185, -0.0440, -0.1631,  0.2100, -0.0969,  0.1017,\n",
       "         -0.1584, -0.1045, -0.0134,  0.0146, -0.0819,  0.0946, -0.0825, -0.1402,\n",
       "          0.1179,  0.0308,  0.1482,  0.0841,  0.0986,  0.0143, -0.3549,  0.0879,\n",
       "          0.0490, -0.1391,  0.1377, -0.1990,  0.0361, -0.0289, -0.0308, -0.0209,\n",
       "         -0.0427, -0.0370,  0.1174, -0.0395, -0.0365, -0.0243, -0.0889, -0.0795,\n",
       "          0.1053,  0.0121, -0.0907, -0.2132,  0.0921, -0.0224, -0.1627, -0.0438,\n",
       "         -0.1984,  0.0576, -0.0609,  0.0790,  0.2034,  0.0105, -0.0762, -0.1267,\n",
       "         -0.0218,  0.0637, -0.1127, -0.0494, -0.1389, -0.1691,  0.0498, -0.0709,\n",
       "          0.0821, -0.0137, -0.0780, -0.1005,  0.0166, -0.1251, -0.1014,  0.1351,\n",
       "         -0.0496,  0.0348, -0.0589, -0.1150,  0.1419,  0.0557, -0.1076,  0.0040,\n",
       "          0.0575, -0.1549,  0.2094, -0.1614, -0.0552,  0.0273, -0.1009,  0.1618,\n",
       "          0.0707,  0.1438,  0.0733, -0.0908, -0.0584, -0.0952, -0.1704, -0.1352,\n",
       "         -0.1287, -0.0403, -0.1419,  0.0645,  0.0336,  0.2317, -0.1326, -0.1056,\n",
       "         -0.0611,  0.0347,  0.0071,  0.0382]),\n",
       " 'mein': tensor([ 2.0567e-01,  6.1084e-01, -3.8953e-01, -2.2124e-01,  1.2140e-01,\n",
       "          3.7500e-01, -2.3138e-01,  1.4831e-01,  2.0053e-01,  4.7262e-01,\n",
       "         -1.2599e-01,  9.4085e-02,  1.4511e-01, -2.1037e-01, -9.7236e-02,\n",
       "         -1.3567e-01, -1.7442e-01,  1.3024e-01, -3.1555e-01, -2.6716e-01,\n",
       "          4.5389e-01,  1.4169e-01, -1.7048e-01, -1.3429e-01, -3.2650e-01,\n",
       "          5.7362e-02,  1.4316e-01, -3.2942e-02, -2.0374e-01, -4.1826e-01,\n",
       "         -6.5192e-02, -1.7699e-01, -1.2950e-01,  2.7343e-02, -3.0567e-01,\n",
       "         -3.8897e-01, -9.9256e-02, -1.3890e-02,  1.4357e-01, -2.4108e-02,\n",
       "          4.4434e-02, -1.6526e-02, -3.3859e-01,  2.4120e-02,  3.8454e-01,\n",
       "         -1.6210e-02, -3.7155e-02,  1.2112e-01, -1.4820e-01, -6.2810e-02,\n",
       "         -3.6796e-01,  5.3258e-01, -1.1326e-02,  3.6225e-01,  3.0412e-02,\n",
       "         -6.6455e-01,  2.9400e-01,  1.5090e-01, -4.5686e-01,  4.4526e-01,\n",
       "         -5.2382e-02, -6.1339e-04, -6.2638e-02, -5.2653e-01, -2.6111e-01,\n",
       "         -7.5648e-01,  8.6729e-02, -1.9083e-01, -3.5255e-01, -4.9673e-02,\n",
       "         -4.3942e-02,  5.2975e-02,  1.3542e-01,  1.9133e-02, -2.7466e-01,\n",
       "         -4.1850e-01,  2.3627e-01,  8.1137e-02, -1.5284e-01, -1.4146e-01,\n",
       "         -1.7386e-01, -2.6154e-01,  1.3544e-01, -5.9356e-02, -2.4980e-01,\n",
       "         -2.7319e-01, -4.7380e-02,  6.4263e-02, -3.9805e-01,  1.8026e-01,\n",
       "         -2.7847e-01, -1.7559e-01,  1.7400e-01,  7.0830e-02,  2.7347e-01,\n",
       "         -5.2552e-01,  2.1775e-01,  3.2149e-01, -3.5639e-01,  1.6600e-01,\n",
       "          5.7192e-02,  2.0011e-01,  6.7914e-02, -5.6862e-02, -6.2717e-02,\n",
       "         -1.1873e-01,  1.0997e-01, -9.6785e-03, -1.0120e-01,  2.9283e-01,\n",
       "          1.0902e-01, -1.0757e-01, -9.9049e-02, -2.1817e-01,  1.0388e-02,\n",
       "          1.7832e-01, -3.3264e-01,  4.9279e-01, -7.3898e-02, -1.3458e-01,\n",
       "          1.1167e-02, -1.1923e-01, -2.6806e-01,  4.3923e-01, -1.3173e-02,\n",
       "          5.7905e-01,  2.0243e-01, -9.1480e-02,  1.8566e-01, -3.7274e-01,\n",
       "          6.0416e-02, -1.0030e-01, -1.8189e-01,  2.3520e-01, -5.2230e-02,\n",
       "          2.3283e-01, -3.0129e-02, -2.3190e-01,  1.5899e-02,  1.5152e-01,\n",
       "         -1.0364e-01, -3.0030e-01, -2.8236e-01,  4.5587e-01, -6.0678e-02,\n",
       "         -1.7270e-01,  6.9061e-02,  4.6124e-01, -5.3857e-04,  1.8703e-01,\n",
       "          3.2378e-01,  3.1364e-01, -4.5260e-01,  3.6226e-02,  1.3992e-01,\n",
       "         -5.5961e-01, -4.4874e-01,  1.7498e-01,  1.9350e-01, -2.8308e-01,\n",
       "         -6.2621e-03,  2.8215e-01,  3.0177e-01, -3.6463e-02, -2.4725e-01,\n",
       "          2.6297e-01, -3.6661e-01, -3.9508e-01, -2.4848e-02,  4.5491e-01,\n",
       "          5.0887e-01, -2.4889e-01,  1.2557e-01, -9.5597e-02,  7.8616e-02,\n",
       "         -6.3831e-02, -4.1039e-01, -1.1930e-01,  3.6496e-01, -3.0448e-01,\n",
       "          2.5681e-02,  4.1629e-01, -4.2981e-02,  5.7832e-02,  2.5857e-01,\n",
       "          4.8889e-01,  1.8952e-01,  1.5092e-01, -9.4240e-02,  7.7337e-02,\n",
       "          1.8901e-03,  2.1276e-01, -3.5161e-02,  2.3446e-01, -3.8937e-01,\n",
       "         -6.9276e-01,  2.5022e-01,  2.3510e-02, -6.9294e-02, -2.8294e-01,\n",
       "         -3.3361e-01, -3.4241e-02, -1.0829e-01,  1.6395e-01, -9.0527e-02,\n",
       "         -4.4969e-03, -1.9115e-01, -5.6752e-01, -2.5618e-01,  1.2532e-01,\n",
       "          3.4763e-01, -3.6547e-01,  3.6117e-01,  1.9681e-01, -5.3505e-01,\n",
       "         -8.6582e-02, -1.1075e-01, -3.1990e-01, -8.0160e-02,  9.3973e-02,\n",
       "         -1.2481e-01, -7.8178e-02,  2.3580e-01,  5.7592e-02, -1.3554e-01,\n",
       "          3.6248e-01,  1.3761e-01,  5.2039e-01, -2.5396e-01, -3.5792e-01,\n",
       "         -1.0054e-01,  4.6170e-02, -3.0184e-02,  5.9082e-02,  3.1008e-01,\n",
       "         -4.2085e-01, -2.8844e-01, -1.3648e-01,  2.2501e-01, -8.4144e-03,\n",
       "         -4.3623e-01,  3.2906e-01,  9.0569e-02, -9.1911e-02,  1.6284e-01,\n",
       "         -1.7073e-02,  1.9944e-01,  2.4139e-01, -1.1036e-01,  1.2571e-01,\n",
       "         -3.4752e-01,  3.1131e-02, -1.3948e-01,  3.9098e-01,  1.5984e-01,\n",
       "          1.7643e-02,  3.1195e-01, -7.9650e-02, -2.6938e-01,  3.2079e-01,\n",
       "          5.4207e-01, -1.9957e-01,  1.6189e-01,  1.9487e-01,  2.0211e-01,\n",
       "         -4.4359e-02, -2.5469e-01, -5.1031e-02, -3.3184e-01,  4.1106e-01,\n",
       "          1.3949e-01, -2.3884e-02,  4.4039e-01,  1.2480e-01,  4.0558e-01,\n",
       "          2.9051e-01,  1.1009e-01,  6.4353e-02,  8.9394e-02,  4.8603e-01,\n",
       "          5.2581e-02,  1.8085e-01,  5.7772e-02,  1.2753e-01,  5.8172e-01,\n",
       "         -1.5712e-01,  1.7154e-02, -1.7846e-01, -1.4906e-01,  3.8052e-01,\n",
       "          7.4151e-02,  2.7614e-01, -4.7293e-02,  4.0081e-01, -8.7956e-02,\n",
       "          5.1652e-02, -8.2217e-02, -5.2867e-01, -6.1580e-03,  3.2919e-01]),\n",
       " 'enkel': tensor([-0.1401,  0.4439, -0.7253, -0.6758,  0.0100,  0.4630, -0.2748, -0.2204,\n",
       "         -0.1936,  0.1436,  0.0707,  0.2291, -0.2687, -0.0822, -0.0964, -0.4439,\n",
       "         -0.4054,  0.3513, -0.3226,  0.1895,  0.3006, -0.0544, -0.4699,  0.7119,\n",
       "          0.1107, -0.0228, -0.1574,  0.3635, -0.5596, -0.3541,  0.2173,  0.2152,\n",
       "         -0.1962,  0.4720, -0.2740, -0.2688, -0.5213, -0.1284, -0.4328,  0.6459,\n",
       "         -0.1077, -0.2522, -0.4704,  0.1982,  0.0700, -0.3389,  0.3085,  0.2665,\n",
       "          0.2850, -0.1586, -0.0162,  0.0534, -0.1332,  0.0943, -0.1089, -0.0576,\n",
       "         -0.3454, -0.1454, -0.3050, -0.0436, -0.1549, -0.6330,  0.1528, -0.7613,\n",
       "         -0.3604,  0.1709, -0.1867, -0.0811, -0.0674, -0.0800, -0.5331, -0.0544,\n",
       "         -0.0064,  0.3404,  0.0591,  0.0386,  0.1869, -0.3428, -0.0227,  0.1236,\n",
       "          0.0693,  0.1084, -0.0328, -0.1823,  0.0453, -0.2568, -0.0507,  0.3551,\n",
       "         -0.1243, -0.3444,  0.0231, -0.0490, -0.2553, -0.1845,  0.0157, -0.3354,\n",
       "          0.1221,  0.2006, -0.1214, -0.0089, -0.0190, -0.0165, -0.3179,  0.0465,\n",
       "         -0.3048,  0.2839, -0.0847,  0.2525,  0.2568, -0.1789, -0.2908, -0.2069,\n",
       "          0.1861, -0.0233, -0.0680,  0.3525,  0.2653, -0.0022,  0.0102, -0.3051,\n",
       "          0.1204,  0.4159,  0.3816,  0.0622, -0.2837,  0.5104,  0.3962, -0.0748,\n",
       "         -0.1505, -0.4171,  0.5855,  0.0708,  0.4897,  0.3451, -0.1104, -0.1402,\n",
       "          0.0801, -0.1181,  0.0886, -0.0018, -0.4311, -0.4626,  0.0410,  0.0936,\n",
       "          0.2219, -0.4334,  0.0887, -0.0541,  0.2048,  0.3624, -0.0374, -0.3918,\n",
       "          0.0328,  0.1893,  0.1573,  0.1495, -0.3061,  0.0624, -0.0152,  0.2295,\n",
       "          0.0245,  0.0698, -0.0379,  0.0194,  0.2176, -0.1735, -0.1620, -0.0605,\n",
       "         -0.1983,  0.1350, -0.3046, -0.1265,  0.0903,  0.0132,  0.2715,  0.1781,\n",
       "          0.0080,  0.0024, -0.4021, -0.3568,  0.1871,  0.1439, -0.0171, -0.0720,\n",
       "          0.0234,  0.1852,  0.1352,  0.0148, -0.4808,  0.2237,  0.2166, -0.2648,\n",
       "         -0.2584, -0.1506,  0.5138, -0.5233, -0.0282,  0.0680, -0.4238,  0.0602,\n",
       "         -0.6091, -0.0467,  0.0039,  0.2903,  0.0671,  0.1418, -0.3414,  0.0088,\n",
       "         -0.1323,  0.2553,  0.3581, -0.3117,  0.4549,  0.0697,  0.1187,  0.2033,\n",
       "         -0.2925, -0.0773, -0.0522,  0.1230,  0.1538,  0.2335, -0.2710, -0.0470,\n",
       "         -0.3274,  0.0525,  0.0092,  0.0718,  0.1712, -0.0661, -0.1629,  0.0023,\n",
       "          0.2346, -0.2596, -0.0157, -0.0738,  0.2810, -0.2674,  0.2086, -0.5820,\n",
       "          0.2583,  0.3595, -0.0854, -0.0171, -0.0430,  0.1652, -0.2366, -0.0771,\n",
       "         -0.3252, -0.0203, -0.2850, -0.0341, -0.1746, -0.0025,  0.3444, -0.4482,\n",
       "          0.4274,  0.0341, -0.2068, -0.1407, -0.2036, -0.3421, -0.0726, -0.0136,\n",
       "          0.0364,  0.2869,  0.1094,  0.1150, -0.0815, -0.2375, -0.0883,  0.2782,\n",
       "         -0.0969,  0.0385,  0.4041, -0.3207, -0.2876, -0.0300, -0.3341,  0.7632,\n",
       "          0.4123,  0.4905, -0.3967, -0.2532,  0.1999,  0.1826, -0.0987,  0.0059,\n",
       "         -0.4227,  0.3070, -0.0334, -0.3460, -0.0301, -0.0552, -0.4915, -0.4531,\n",
       "          0.1250, -0.1539, -0.1798,  0.1362]),\n",
       " 'lukas': tensor([-0.6889, -0.2031, -0.5929, -0.1915, -0.3564,  0.4656,  0.1012, -0.3020,\n",
       "          0.3868,  0.1535, -0.1793, -0.1376, -0.3477,  0.1506, -0.0358,  0.1782,\n",
       "         -0.1758,  0.7257, -0.3359,  0.1405,  0.1144,  0.3394,  0.1292, -0.2507,\n",
       "          0.1765, -0.0441,  0.1128,  0.1642, -0.1511, -0.4164,  0.2162, -0.0661,\n",
       "          0.0472, -0.3875, -0.3350, -0.1577, -0.0562,  0.1664,  0.2026,  0.3302,\n",
       "          0.3993,  0.2407,  0.1601, -0.2602, -0.2340, -0.0517,  0.5095,  0.0319,\n",
       "         -0.3370, -0.4400,  0.3076,  0.4167,  0.0862,  0.0329, -0.1902,  0.1484,\n",
       "         -0.0772,  0.2330,  0.0640, -0.3602,  0.2785,  0.0028,  0.4636, -0.1695,\n",
       "         -0.3151, -0.2539, -0.0972,  0.2240, -0.2962,  0.1118, -0.2755, -0.1270,\n",
       "          0.1953,  0.6912, -0.1742, -0.3340,  0.1218, -0.4846, -0.2674,  0.3141,\n",
       "         -0.0156,  0.0487, -0.0910, -0.2060, -0.3299, -0.3752,  0.4148,  0.4835,\n",
       "          0.1683, -0.0450, -0.1930,  0.0009,  0.3976, -0.0358, -0.1377, -0.2025,\n",
       "          0.3746,  0.5648, -0.1043,  0.2555,  0.4291, -0.2725, -0.2079,  0.1200,\n",
       "          0.3128,  0.1939,  0.1702,  0.4563, -0.0632,  0.2965, -0.2761,  0.0793,\n",
       "          0.1357,  0.2185, -0.1220,  0.2156,  0.2153, -0.3256, -0.4412,  0.0443,\n",
       "         -0.1384, -0.1398,  0.3264, -0.1070,  0.0750,  0.4198,  0.3123,  0.3315,\n",
       "         -0.2432,  0.4963, -0.0022, -0.5079,  0.1561,  0.0502,  0.4340,  0.3491,\n",
       "         -0.2197,  0.0097,  0.3987,  0.0722,  0.1017, -0.0172,  0.4430,  0.6556,\n",
       "          0.0405, -0.1922, -0.2103, -0.0417,  0.1986,  0.2277,  0.4125,  0.1095,\n",
       "         -0.0374, -0.2662, -0.0871, -0.4889, -0.0789,  0.6765, -0.0048,  0.0369,\n",
       "          0.0417,  0.2298,  0.0462,  0.1602, -0.2709, -0.0923,  0.0041, -0.3689,\n",
       "         -0.5022,  0.1059, -0.4547, -0.3621, -0.0175, -0.1698, -0.2753,  0.1751,\n",
       "          0.2698, -0.3908,  0.0141,  0.0707, -0.0173, -0.2751, -0.2245, -0.5113,\n",
       "         -0.1121, -0.2113,  0.1318,  0.2641, -0.5239, -0.1650, -0.1751, -0.1810,\n",
       "         -0.3548, -0.2650, -0.1755,  0.2579,  0.4504,  0.1602, -0.1627, -0.3361,\n",
       "          0.2336,  0.7116, -0.1281, -0.2975, -0.1482, -0.0497, -0.1177, -0.0526,\n",
       "          0.5475, -0.0880,  0.2444, -0.0171,  0.0446, -0.1117, -0.4881,  0.5670,\n",
       "          0.6283,  0.3352, -0.1705,  0.0326,  0.4705, -0.0080,  0.2158,  0.2592,\n",
       "         -0.0842,  0.3000, -0.1035,  0.3411, -0.1243,  0.1399,  0.0501, -0.0984,\n",
       "          0.1279,  0.1896,  0.1275, -0.2899, -0.2272, -0.1222,  0.2798,  0.3080,\n",
       "         -0.0083,  0.1519, -0.0985, -0.2058,  0.0518,  0.1620,  0.1766,  0.3401,\n",
       "          0.0442, -0.0816,  0.0852,  0.2600,  0.2458, -0.5566,  0.0104, -0.1999,\n",
       "          0.5039,  0.0646, -0.0636,  0.3129,  0.0465, -0.1575,  0.5793,  0.1689,\n",
       "         -0.0099,  0.3796,  0.1851,  0.1488,  0.3470, -0.2199, -0.0214,  0.3417,\n",
       "          0.1678, -0.0072,  0.4519, -0.3098, -0.0341, -0.2164,  0.0207,  0.8442,\n",
       "         -0.0610,  0.5218, -0.4441,  0.1425,  0.1658, -0.1330, -0.4487, -0.3466,\n",
       "         -0.2145,  0.1690, -0.0386,  0.3462,  0.2502,  0.2048, -0.0114, -0.1613,\n",
       "         -0.0647, -0.2574, -0.2307,  0.1795]),\n",
       " 'fliegen': tensor([-2.0774e-01,  1.8156e-01, -2.1997e-01, -1.7901e-01,  2.1162e-01,\n",
       "         -3.1659e-01,  3.3202e-01,  1.0589e-01, -9.9981e-02, -9.2828e-02,\n",
       "          3.9514e-01,  1.7547e-01,  3.9157e-01, -2.1321e-01, -9.2921e-01,\n",
       "         -7.0327e-02,  3.9267e-01,  3.5244e-01, -1.0407e-01,  2.6723e-01,\n",
       "         -1.3514e-02,  2.3807e-01, -1.3464e-01,  1.4714e-01, -1.8182e-01,\n",
       "         -5.4181e-01, -2.3780e-01, -1.5526e-01, -3.1450e-01,  6.2375e-02,\n",
       "         -5.7544e-01,  2.3932e-02,  2.8907e-01, -4.8173e-01,  2.8975e-01,\n",
       "         -7.2744e-02,  1.1058e-01, -5.8936e-02,  5.8959e-02,  7.2680e-02,\n",
       "          2.7754e-01, -2.3411e-01, -7.7917e-02,  3.3146e-01,  5.4730e-01,\n",
       "         -5.3527e-02,  1.0230e-01, -5.8724e-01,  5.3481e-02, -2.8313e-01,\n",
       "         -1.9339e-02,  3.4146e-01, -4.7587e-02, -6.2714e-02,  6.2483e-01,\n",
       "         -2.9565e-01, -8.4457e-02,  4.7737e-02,  1.6841e-01,  2.9362e-01,\n",
       "          2.2558e-01,  2.8378e-01,  4.1094e-01, -2.9983e-01, -5.4627e-01,\n",
       "         -1.5983e-02, -2.0032e-01,  2.3184e-01, -2.0477e-01,  4.3578e-01,\n",
       "         -1.5980e-01,  3.3492e-01, -4.9569e-01,  6.2541e-01, -2.1568e-01,\n",
       "         -7.2398e-02,  2.3752e-01,  2.3765e-01, -4.1763e-01,  2.0817e-02,\n",
       "         -2.6177e-01, -3.1304e-01,  9.4457e-02, -1.3336e-01, -1.5640e-01,\n",
       "         -3.6121e-01,  1.8873e-01, -1.2159e-01, -6.0877e-01, -2.9476e-01,\n",
       "          5.1461e-02,  1.2411e-01,  2.1092e-01, -1.8349e-01,  1.9352e-01,\n",
       "         -3.6543e-02, -1.6589e-02, -3.0914e-01,  2.3890e-01, -1.2054e-01,\n",
       "          3.0691e-01,  3.7203e-01, -1.0162e-01, -9.6232e-02,  4.3902e-02,\n",
       "         -3.5527e-01,  5.2533e-02,  8.1823e-02, -2.3001e-01,  3.5797e-01,\n",
       "          5.5623e-02, -2.3444e-01, -9.6291e-03,  1.0252e-02,  2.7691e-01,\n",
       "          1.4949e-02, -4.7020e-01,  2.3144e-02,  3.2276e-01,  1.2320e-01,\n",
       "          1.2237e-01, -4.1983e-01, -1.4544e-01, -9.0763e-02, -1.7946e-01,\n",
       "         -4.5547e-02, -1.5006e-01, -2.2899e-02,  3.4093e-01,  6.9398e-03,\n",
       "          4.4324e-02, -1.3871e-01,  1.1367e-01,  4.6732e-01, -8.0299e-02,\n",
       "          3.1760e-01,  2.7253e-01,  5.0066e-01,  3.6511e-01, -1.6974e-01,\n",
       "         -1.6108e-01, -4.2128e-02, -3.1040e-01,  3.6455e-01, -1.9288e-01,\n",
       "         -3.4920e-01,  4.8304e-01, -2.1404e-02, -5.0584e-01,  2.3389e-01,\n",
       "          3.5048e-01,  7.5011e-02, -3.7384e-02, -1.0447e-01, -7.6627e-04,\n",
       "         -1.3185e-01, -2.1978e-01,  4.2745e-01,  4.2058e-01,  3.2583e-01,\n",
       "         -3.7940e-01,  6.5568e-02, -2.4660e-01,  2.1430e-01, -1.8437e-01,\n",
       "          4.2615e-01, -1.4403e-01, -1.6166e-01, -3.9664e-01, -1.3009e-01,\n",
       "         -2.6746e-01, -6.2126e-02,  5.2183e-01,  1.6572e-01, -1.1692e-03,\n",
       "          2.1330e-01,  2.8538e-01,  4.2190e-01,  1.4049e-01, -3.5717e-01,\n",
       "          3.5560e-01,  2.2117e-01, -3.4352e-01,  3.3952e-02,  1.2763e-01,\n",
       "         -9.1422e-03,  5.4431e-02, -5.2403e-01, -2.6486e-01,  2.3308e-01,\n",
       "          8.0522e-02, -1.2860e-01,  3.2769e-01,  2.8337e-02,  8.0314e-02,\n",
       "         -4.5159e-01, -9.3090e-03,  3.9007e-01, -4.5855e-01, -1.8065e-01,\n",
       "          7.4523e-02,  2.7426e-01,  4.3878e-01, -1.2834e-01, -3.1178e-01,\n",
       "          3.9473e-01, -1.1915e-01, -2.5479e-01,  1.1166e-01,  6.4247e-02,\n",
       "         -2.3302e-01, -2.0038e-01,  2.2462e-01, -3.0226e-01, -1.5013e-01,\n",
       "         -7.5991e-02,  2.5460e-01, -2.1927e-01,  6.9774e-02, -1.8683e-01,\n",
       "         -3.2241e-01,  1.4303e-01, -1.8684e-01, -2.6044e-02,  3.1834e-01,\n",
       "          7.9420e-02, -1.8277e-02,  9.0024e-02, -1.4045e-01,  5.2125e-01,\n",
       "          2.8446e-01, -2.2866e-01, -9.5816e-02,  2.3224e-01, -5.2163e-01,\n",
       "          1.6878e-01,  2.9737e-01, -4.3719e-01, -4.2018e-01,  2.3079e-01,\n",
       "          4.2910e-02, -1.4151e-01, -1.9992e-01, -3.6252e-02,  9.5918e-02,\n",
       "         -1.0591e-01, -1.9790e-01,  3.7335e-01,  2.3717e-01,  2.2709e-01,\n",
       "         -6.3778e-01,  1.8206e-01,  1.0015e-01, -1.3813e-01,  1.3495e-02,\n",
       "         -1.7960e-01,  1.0728e-01, -5.6321e-01, -2.6256e-01, -2.8605e-02,\n",
       "          4.3929e-01, -4.8762e-01, -3.1730e-01,  1.9718e-01,  4.7222e-04,\n",
       "          1.9054e-01,  1.7426e-01, -1.6713e-01, -4.6004e-01, -4.2661e-01,\n",
       "          1.1931e-01, -3.5777e-01,  2.7435e-01, -3.0019e-01, -1.5893e-01,\n",
       "         -1.0334e-01, -6.1702e-02,  6.0296e-01,  2.7161e-01,  8.1993e-01,\n",
       "          3.7801e-01, -6.5228e-02,  3.7974e-01,  7.8070e-02, -5.2103e-02,\n",
       "         -3.7575e-01, -6.8463e-02,  2.0887e-02, -2.4816e-01,  3.3316e-01,\n",
       "         -3.5142e-01,  3.4537e-03,  3.8660e-01,  2.9887e-01, -4.3223e-01,\n",
       "          2.5935e-01, -3.6943e-01, -1.4646e-01,  4.2302e-03,  2.3830e-01]),\n",
       " 'morgen': tensor([-3.4325e-01,  2.9281e-01, -2.8438e-01, -5.7771e-01,  3.3743e-01,\n",
       "          2.1802e-01, -1.9848e-01, -1.6503e-01, -4.3377e-01,  8.2734e-02,\n",
       "          3.2548e-01,  2.4994e-01, -3.1397e-01,  2.6400e-02, -4.1054e-01,\n",
       "          1.4687e-01,  9.6374e-02,  1.9633e-01,  8.0607e-02,  2.5361e-02,\n",
       "          1.9844e-01,  1.0095e-01,  3.3831e-02,  3.0233e-01, -2.0825e-01,\n",
       "         -1.3769e-01,  4.8724e-02,  1.5217e-01, -2.3885e-01,  8.2112e-02,\n",
       "         -1.7253e-01,  1.4224e-01, -8.4728e-03,  2.6609e-01, -2.9130e-01,\n",
       "          2.3415e-01, -3.2346e-01,  2.2188e-01, -1.3867e-01, -3.1281e-01,\n",
       "          5.3976e-01,  7.6830e-02, -1.5300e-01,  3.0060e-01, -1.8391e-01,\n",
       "          6.3880e-01, -2.5048e-01,  1.7048e-01, -1.3974e-01, -2.2924e-01,\n",
       "         -3.7393e-02, -2.1227e-01, -2.9316e-03,  1.2489e-01, -1.7441e-02,\n",
       "         -3.5312e-02, -1.0579e-02, -1.6943e-01, -4.0569e-01, -5.3231e-02,\n",
       "          1.6445e-01,  1.0832e-01,  4.8410e-01,  5.2760e-02, -5.2573e-02,\n",
       "         -3.8449e-01, -1.2195e-01, -9.6558e-02,  9.9439e-02,  2.3439e-01,\n",
       "          1.2350e-02,  9.6106e-02, -2.7491e-01,  5.3899e-02, -4.0446e-01,\n",
       "          8.3134e-02,  1.4845e-01, -2.3344e-01,  4.6395e-01,  1.1569e-01,\n",
       "         -3.1269e-01, -2.4293e-01,  3.2243e-02, -1.5885e-01, -2.7318e-01,\n",
       "         -2.1020e-01,  2.3411e-01,  3.8558e-01, -1.9781e-01,  2.0858e-01,\n",
       "         -1.6798e-02, -1.1102e-01,  1.0184e-02,  6.8619e-02, -7.9344e-02,\n",
       "         -1.3877e-01, -1.3538e-01,  2.4559e-01, -4.4724e-01, -1.0617e-01,\n",
       "          5.4670e-01,  3.2757e-01, -2.9631e-01, -3.3643e-01,  1.3371e-01,\n",
       "         -5.4077e-02, -8.6688e-03, -1.1076e-01, -5.4636e-01, -1.6683e-01,\n",
       "          2.1855e-02,  7.0201e-02,  3.3354e-01,  3.5489e-01,  4.9079e-01,\n",
       "         -1.2895e-01, -4.4580e-01,  1.3516e-01, -2.3138e-01, -3.0242e-01,\n",
       "         -1.1690e-01, -2.9349e-01,  2.1127e-01,  2.4937e-01, -2.5677e-01,\n",
       "          3.3829e-01,  3.9594e-01,  1.1432e-01, -6.8485e-02,  1.0492e-01,\n",
       "          3.2846e-01,  2.7283e-02, -4.4968e-01,  2.6652e-01,  3.7191e-03,\n",
       "          8.8928e-03, -1.8476e-01,  1.1784e-01,  1.6759e-01, -1.3239e-02,\n",
       "          1.0033e-01, -5.1866e-02,  3.1697e-02,  5.3488e-01,  1.3949e-01,\n",
       "          4.1278e-02, -7.4719e-02, -2.9714e-01,  2.0013e-02,  3.9450e-01,\n",
       "          2.4104e-01,  1.8232e-01, -1.7363e-01,  9.9727e-02, -4.1488e-01,\n",
       "         -9.0057e-02, -2.7265e-01,  4.5391e-01,  2.9916e-01, -3.8612e-02,\n",
       "          2.0329e-01, -2.0787e-03, -6.2344e-01, -7.6216e-02, -5.0347e-02,\n",
       "         -1.3289e-01, -3.5976e-01, -2.8326e-01, -2.5967e-01,  5.7932e-01,\n",
       "         -2.7484e-02, -4.4675e-01,  3.6416e-01, -6.7418e-02,  2.1059e-02,\n",
       "         -2.1835e-01, -1.9236e-01,  1.4846e-01, -1.8122e-01, -3.1634e-01,\n",
       "         -1.0211e-01,  1.4102e-01,  2.5538e-03,  2.6162e-02,  1.1886e-04,\n",
       "          2.7687e-01, -1.0139e-01,  1.1722e-02,  1.7908e-01,  5.1524e-02,\n",
       "          2.4968e-01,  8.0012e-02, -1.1145e-01, -2.0734e-01,  2.3796e-01,\n",
       "          1.1838e-01,  1.1156e-01, -3.2937e-03, -5.3046e-01, -1.5294e-01,\n",
       "         -1.3588e-01, -3.4891e-01,  1.7577e-01,  2.6835e-01, -1.9744e-02,\n",
       "         -2.1074e-01, -1.2375e-01, -1.5732e-01,  9.6965e-02,  1.2455e-01,\n",
       "          2.0939e-02, -7.2160e-02,  4.9835e-01,  1.2897e-01, -3.4024e-01,\n",
       "          8.1743e-02, -3.5140e-01, -9.3572e-02,  3.4482e-01, -8.9756e-02,\n",
       "         -2.1075e-01,  3.8665e-02,  1.6552e-01,  7.4986e-02, -1.9486e-01,\n",
       "          6.4312e-02,  1.1607e-01, -1.9621e-01,  3.5238e-01, -2.7191e-01,\n",
       "         -1.4742e-02, -3.4625e-01, -1.4203e-02, -2.3368e-01,  1.3273e-02,\n",
       "          2.3900e-01, -2.2685e-01, -3.8782e-01, -1.2200e-01,  1.8636e-01,\n",
       "         -2.6686e-02, -4.3226e-01, -2.1732e-01, -1.2904e-01, -1.6311e-01,\n",
       "          1.5538e-01,  3.5157e-01,  1.6317e-01, -2.4509e-01,  2.1255e-01,\n",
       "         -4.6439e-01,  4.3215e-01, -2.2703e-01, -2.2182e-01,  1.3042e-02,\n",
       "         -9.3873e-02, -1.1768e-01, -6.3359e-01, -1.4306e-01, -2.4772e-01,\n",
       "          7.7296e-01, -2.5705e-01, -2.0226e-01,  2.7186e-01,  1.1687e-01,\n",
       "          1.6379e-01, -4.0329e-02, -5.2326e-02, -7.4964e-02,  1.4717e-01,\n",
       "         -1.7409e-01, -1.9685e-01,  3.8464e-01,  2.0955e-01,  6.2918e-01,\n",
       "         -2.7716e-02,  1.4143e-01,  1.6781e-01, -2.3969e-01,  3.5785e-01,\n",
       "          5.3793e-01, -3.3034e-01,  3.3023e-01,  3.9821e-01,  8.5378e-02,\n",
       "         -1.7727e-01, -5.5465e-01,  2.9757e-02,  1.7413e-01, -1.0863e-01,\n",
       "          8.5262e-02, -2.5500e-02,  5.1663e-01,  4.6038e-01, -1.8492e-02,\n",
       "          3.2210e-01,  6.1795e-03,  8.1319e-02,  1.1421e-01,  2.9934e-01]),\n",
       " 'nach': tensor([-0.1516,  0.1955, -0.2335, -0.1729, -0.0212,  0.3123,  0.0564,  0.1527,\n",
       "         -0.1676,  0.2313,  0.0097,  0.0846, -0.1150,  0.1930, -0.1226, -0.1958,\n",
       "         -0.1849,  0.1303,  0.1425,  0.1543, -0.0477,  0.3187, -0.1185,  0.1491,\n",
       "          0.0682, -0.0372,  0.2324,  0.1129, -0.1757, -0.1372, -0.1462,  0.1264,\n",
       "          0.1258, -0.1010, -0.0930, -0.0114, -0.0182, -0.1655, -0.3224, -0.0369,\n",
       "         -0.2343, -0.1226, -0.3129,  0.2397,  0.0423, -0.5976,  0.0524,  0.1709,\n",
       "          0.1463,  0.2196,  0.1585,  0.0007,  0.2736,  0.1648,  0.1445,  0.0075,\n",
       "          0.0339,  0.1693,  0.2439, -0.3102, -0.2215,  0.2965, -0.0109, -0.0017,\n",
       "         -0.5345, -0.3783, -0.0214,  0.1356,  0.0695,  0.1659, -0.3862, -0.1836,\n",
       "         -0.2092,  0.0404, -0.1469, -0.2054, -0.0332, -0.0776, -0.1764,  0.1130,\n",
       "         -0.0694, -0.0884, -0.1539,  0.1814, -0.0257, -0.0966,  0.1295, -0.0325,\n",
       "         -0.2186, -0.1800,  0.3295,  0.0882, -0.0534, -0.0906,  0.1167, -0.0591,\n",
       "          0.1275,  0.1355, -0.0758, -0.0179,  0.1971,  0.0919, -0.0973,  0.0988,\n",
       "          0.4103,  0.0955, -0.0866,  0.1262,  0.1678, -0.1328,  0.1109,  0.2585,\n",
       "         -0.0507,  0.1902, -0.0181,  0.0496,  0.2896,  0.1102, -0.3057,  0.1044,\n",
       "          0.0707,  0.2173, -0.0125,  0.1102, -0.1761, -0.0573, -0.0690,  0.3865,\n",
       "          0.1459,  0.0547,  0.1454, -0.1668, -0.0533,  0.0084,  0.1336,  0.0776,\n",
       "         -0.1269, -0.0130,  0.0641, -0.1063, -0.0627,  0.0742, -0.2113,  0.0253,\n",
       "         -0.2284, -0.1670, -0.0496, -0.2324, -0.0317,  0.0090,  0.1141, -0.5118,\n",
       "          0.0019, -0.0245, -0.2975, -0.2345, -0.3007,  0.0357, -0.0403,  0.0417,\n",
       "          0.1811, -0.1580, -0.0861,  0.0077, -0.1407,  0.0059,  0.0067, -0.0810,\n",
       "         -0.1175,  0.3013, -0.0121, -0.0022, -0.2259,  0.1315,  0.2396, -0.0541,\n",
       "          0.0846, -0.1576,  0.0791, -0.0575, -0.0229,  0.1901,  0.0024,  0.0990,\n",
       "         -0.1713, -0.0193,  0.0787, -0.1122, -0.3358,  0.0011, -0.0555, -0.0542,\n",
       "          0.1598,  0.1485, -0.2313, -0.0720,  0.1422,  0.1621, -0.0067, -0.2522,\n",
       "         -0.3853, -0.0055,  0.0788,  0.1800, -0.2077,  0.1258,  0.2670,  0.1823,\n",
       "         -0.1612, -0.0502,  0.4797,  0.2014, -0.0647,  0.0407, -0.3641,  0.2508,\n",
       "          0.0191, -0.0023,  0.2326, -0.2187,  0.0802,  0.2594,  0.0848, -0.0841,\n",
       "          0.1332,  0.1324,  0.0208, -0.1476,  0.1465, -0.1256,  0.0165, -0.1192,\n",
       "         -0.0858, -0.0614,  0.0247, -0.2299, -0.0920,  0.0335,  0.0908, -0.1144,\n",
       "          0.1883,  0.0671,  0.1084, -0.2130,  0.1877, -0.1715, -0.1009,  0.0032,\n",
       "         -0.2516,  0.2637, -0.1449, -0.1010, -0.1136,  0.0291,  0.2642,  0.0462,\n",
       "          0.0997, -0.1663,  0.0937,  0.0480,  0.2226, -0.0177, -0.2417, -0.0929,\n",
       "         -0.0236,  0.0091,  0.0614,  0.1047,  0.0593, -0.0813, -0.2094, -0.1425,\n",
       "         -0.0208, -0.2972,  0.0190, -0.2906,  0.1014,  0.0011, -0.0829,  0.2489,\n",
       "         -0.1171,  0.3047,  0.0888,  0.1458, -0.0648,  0.0943, -0.2631, -0.0505,\n",
       "         -0.1531, -0.0912,  0.0780,  0.2149,  0.1661,  0.1774, -0.3742, -0.0088,\n",
       "         -0.3219,  0.1283,  0.0261,  0.1005]),\n",
       " 'london': tensor([-2.0543e-01,  5.3766e-01,  1.1839e-01,  1.7434e-01, -1.9048e-01,\n",
       "          1.1346e-01,  4.3042e-02, -2.7831e-01,  2.6059e-01,  7.1253e-01,\n",
       "         -3.7493e-01, -2.1817e-01,  1.3900e-02, -1.4697e-01,  3.5145e-02,\n",
       "         -5.1498e-02, -5.5761e-01,  1.9687e-01, -2.8718e-01,  3.7205e-02,\n",
       "          6.2623e-02,  5.7264e-02, -4.0090e-01, -2.0298e-01,  9.1011e-02,\n",
       "          1.0494e-01,  1.1177e-01, -1.0363e-01, -4.3171e-01, -3.3312e-01,\n",
       "         -3.0482e-01,  2.4999e-01,  3.1518e-01, -3.9136e-01, -1.5438e-01,\n",
       "          5.0649e-04, -4.2391e-01, -5.4262e-02, -4.1129e-01,  4.7684e-01,\n",
       "          1.5494e-01, -1.0750e-01,  1.5441e-01,  2.5798e-01, -3.5377e-02,\n",
       "         -3.4795e-01,  4.5134e-01, -1.2613e-01, -6.3186e-03,  1.6695e-01,\n",
       "         -2.6414e-01, -8.1829e-02,  3.4749e-01,  1.5782e-01,  3.0179e-01,\n",
       "         -9.6368e-02, -5.9277e-01,  2.3807e-01,  1.2207e-02, -4.1713e-01,\n",
       "         -1.3644e-01, -2.1313e-01,  3.4304e-01,  9.4681e-02, -1.7936e-01,\n",
       "          3.3903e-01, -2.2869e-01,  1.0562e-01, -5.6877e-02, -5.1594e-01,\n",
       "         -2.5602e-01, -4.1397e-02,  3.2604e-03, -5.3836e-03, -5.1261e-02,\n",
       "         -2.6751e-02,  7.5210e-02,  5.4155e-01,  9.8480e-02,  1.9252e-01,\n",
       "         -5.8564e-01, -5.6658e-01, -5.1472e-02,  2.8324e-01,  2.5921e-03,\n",
       "         -1.0206e-01,  3.2496e-01, -2.6235e-02,  3.1205e-01, -2.5035e-01,\n",
       "         -1.2592e-01,  3.1779e-01,  2.0824e-01, -3.1221e-01,  1.3585e-01,\n",
       "         -2.8495e-01,  8.7865e-02,  6.6035e-01, -4.7460e-02,  3.4897e-03,\n",
       "         -1.4379e-03,  4.2262e-02, -6.2413e-02, -2.1491e-01,  1.5569e-02,\n",
       "         -2.3536e-02, -1.5375e-01,  2.9955e-01, -1.5191e-01, -2.2183e-01,\n",
       "         -1.1942e-01, -1.9281e-01,  1.5945e-03, -4.3241e-02,  1.1828e-01,\n",
       "         -8.9744e-02,  1.8364e-01,  3.6669e-01,  5.1654e-02,  4.8154e-01,\n",
       "         -4.3712e-01,  2.8944e-01,  1.2544e-01,  6.5629e-02, -1.4105e-01,\n",
       "          8.2197e-02,  6.2526e-01,  2.6945e-01, -1.7522e-01,  1.4907e-01,\n",
       "          6.9481e-02, -1.9016e-01, -9.6645e-02,  1.9869e-01,  2.2506e-02,\n",
       "         -9.5864e-02, -3.3559e-01,  5.9583e-02, -7.9991e-02, -4.2421e-01,\n",
       "         -8.3673e-01,  5.7089e-01, -1.3477e-01,  3.5691e-01,  2.1664e-01,\n",
       "         -3.6575e-01, -3.9844e-02,  1.5396e-01, -1.8837e-02,  1.2810e-01,\n",
       "          6.9259e-01, -3.4327e-01, -1.3342e-01, -3.4089e-02, -1.3281e-01,\n",
       "          3.9471e-01, -2.1644e-01,  3.9317e-01,  1.9515e-01,  4.2840e-03,\n",
       "         -3.1215e-01,  6.1175e-01,  1.1828e-01,  1.4888e-02, -6.7877e-02,\n",
       "          1.3817e-01,  4.3739e-01, -3.8451e-01, -4.1760e-01, -3.4288e-01,\n",
       "         -2.1007e-01, -2.0780e-01,  6.3763e-02,  5.5756e-01, -7.7768e-02,\n",
       "          1.5810e-01, -1.6799e-02, -4.1558e-02,  1.5499e-01,  3.4771e-01,\n",
       "          4.1722e-01,  1.9641e-01, -1.8988e-02,  2.2773e-02,  4.3433e-01,\n",
       "          1.4149e-01,  5.2231e-02, -4.4368e-01,  6.8695e-02,  2.6331e-01,\n",
       "          2.3108e-01, -2.3184e-01,  4.2875e-01,  6.7212e-02,  9.6530e-02,\n",
       "         -1.3185e-01, -1.4558e-01,  1.2020e-01, -3.5771e-01, -2.4056e-02,\n",
       "          4.2728e-01, -2.8174e-02,  2.6762e-01,  3.1640e-01,  1.1352e-01,\n",
       "          1.8087e-01, -3.5552e-01,  2.1574e-02, -2.0673e-02, -2.3772e-01,\n",
       "         -1.9400e-01,  4.7855e-02, -5.5183e-02,  2.6058e-01, -4.3035e-01,\n",
       "         -9.8725e-02, -1.6568e-01, -3.3884e-01,  1.7502e-01, -1.6568e-01,\n",
       "          6.7561e-02, -4.9963e-02,  8.0181e-02,  8.2347e-02, -2.1902e-01,\n",
       "          3.0588e-01,  2.5135e-02, -5.5910e-01,  5.2268e-02, -1.4720e-01,\n",
       "         -1.3917e-03,  1.9368e-02, -1.7176e-01,  1.4015e-01, -2.1799e-01,\n",
       "         -1.0576e-01, -4.7346e-01, -2.2746e-02, -1.1724e-01, -6.6509e-02,\n",
       "          6.6954e-02,  9.4607e-02,  6.6609e-02,  3.8411e-02,  2.4979e-01,\n",
       "          8.1899e-03, -4.3628e-03,  2.0809e-01, -2.8098e-02,  5.4406e-01,\n",
       "         -2.7763e-01, -1.2492e-01, -2.1188e-01,  2.0321e-01, -5.2977e-01,\n",
       "         -1.8715e-01, -7.4231e-02, -3.9795e-01, -4.4451e-01, -1.5403e-02,\n",
       "         -5.7321e-02, -2.5931e-02,  2.1538e-01, -1.4180e-01,  5.6759e-02,\n",
       "          9.6845e-02, -8.4151e-02, -7.2121e-02, -2.6370e-02, -5.5877e-03,\n",
       "         -2.3731e-01,  3.4942e-01, -1.2230e-01, -4.2815e-01, -1.0043e-01,\n",
       "         -1.4596e-01,  3.4882e-01,  1.0435e-01, -1.1943e-01, -2.3076e-01,\n",
       "          1.8803e-01,  2.8795e-01,  2.9419e-01,  1.1995e-01,  2.2324e-02,\n",
       "          2.4689e-01, -3.6943e-01, -4.2236e-01, -1.4266e-01,  1.7109e-01,\n",
       "         -1.6760e-01, -8.2845e-02,  2.7938e-01,  3.1906e-01,  1.6054e-01,\n",
       "         -8.8747e-02, -4.0831e-01, -4.9437e-01, -1.5186e-02,  3.5138e-01])}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flair.data import Sentence, Token\n",
    "from flair.embeddings import WordEmbeddings\n",
    "\n",
    "flair_embeddings = {}\n",
    "for sentence in sent_tokenize(text):\n",
    "    sentence = re.sub(r'\\W', ' ', sentence)\n",
    "    sentence = re.sub(r'\\s{2,}', ' ', sentence)    \n",
    "    \n",
    "    sentence = Sentence(sentence.lower())\n",
    "    glove_embedding = WordEmbeddings('de')\n",
    "    #glove_embedding = WordEmbeddings('de-crawl')\n",
    "    glove_embedding.embed(sentence)\n",
    "    \n",
    "    for token in sentence:\n",
    "        flair_embeddings[token.text] = token.embedding\n",
    "\n",
    "flair_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([-1.1571e+00,  2.3111e-01, -1.9308e+00, -1.1682e+00, -7.4470e-01,\n",
       "          1.1951e+00, -4.3329e-01, -3.0150e-01,  7.1854e-01,  5.3736e-01,\n",
       "         -1.7087e-01, -6.7910e-02, -5.5695e-01, -1.9679e-01, -3.5563e-02,\n",
       "         -1.5552e-01, -4.9553e-01,  1.1511e+00, -7.0194e-01,  6.2212e-01,\n",
       "          5.3428e-01,  5.3036e-01,  1.9694e-02,  9.1691e-01, -6.9134e-02,\n",
       "         -2.2981e-01,  2.1040e-02,  1.1885e+00, -7.1146e-01, -1.1373e+00,\n",
       "          7.3750e-01,  1.5989e-01,  2.8375e-02, -5.0487e-01, -1.1745e+00,\n",
       "         -1.0308e+00, -6.5149e-01,  1.4186e-01, -6.0350e-01,  8.0303e-01,\n",
       "         -1.6300e-03, -4.1764e-01, -4.0262e-01,  2.1460e-03, -4.1026e-01,\n",
       "         -7.3068e-01,  8.4265e-01, -3.1099e-01, -5.0911e-01, -7.4222e-01,\n",
       "          5.0225e-01,  6.8844e-01,  5.9872e-01,  5.5705e-02, -2.7957e-01,\n",
       "         -2.9116e-01, -4.7137e-01,  1.6188e-01, -2.0561e-01, -3.8416e-01,\n",
       "          1.1123e-02, -7.6916e-01,  1.4325e+00, -7.4875e-01, -8.6174e-01,\n",
       "         -4.9399e-01, -9.8840e-02,  6.0916e-01, -6.1926e-01,  3.3192e-01,\n",
       "         -1.2810e+00, -4.0659e-01, -2.7177e-02,  1.1945e+00, -3.2305e-01,\n",
       "         -2.7817e-01,  1.9641e-01, -1.1798e+00, -3.4814e-01,  8.1192e-01,\n",
       "          2.9021e-01, -6.6750e-02, -1.0321e-02, -1.7299e-01, -6.8707e-01,\n",
       "         -6.5709e-01,  7.2941e-01,  1.2979e+00, -3.0908e-01, -2.8060e-01,\n",
       "         -5.7759e-01,  1.5237e-01,  3.5665e-01, -4.9849e-01, -5.4589e-02,\n",
       "         -7.7133e-01,  4.5691e-01,  1.4774e+00, -9.5272e-01,  5.3983e-01,\n",
       "          8.6862e-01,  6.0277e-02, -3.1754e-01, -1.2272e-01,  7.0823e-01,\n",
       "          8.7169e-01, -2.0977e-01,  1.2028e+00,  9.2625e-02,  4.4479e-01,\n",
       "         -4.5444e-01,  2.9942e-01,  5.6466e-01,  2.3062e-01,  6.1480e-02,\n",
       "          4.7532e-01,  2.2778e-01, -1.5998e-01, -9.0376e-01, -2.2181e-01,\n",
       "          9.5685e-02,  2.9138e-01,  1.3088e+00,  4.7565e-01, -4.8901e-04,\n",
       "          1.2019e+00,  1.0534e+00,  2.8543e-01, -5.8544e-01,  3.5472e-01,\n",
       "          3.0544e-01, -4.2422e-01,  8.6940e-01,  7.2609e-01,  6.7906e-01,\n",
       "          2.0668e-01, -4.5298e-01,  8.6188e-02,  1.0581e+00, -2.2621e-01,\n",
       "         -7.0036e-01, -3.3699e-01,  9.7917e-01,  1.1307e+00,  3.6630e-01,\n",
       "         -9.4039e-01,  2.0634e-01, -8.7127e-02,  4.5478e-01,  7.1453e-01,\n",
       "          7.0034e-01,  7.1405e-02, -1.9764e-01,  4.1235e-01,  3.7073e-01,\n",
       "         -2.8570e-01, -7.3916e-01,  1.3709e+00,  6.6767e-01,  5.8566e-01,\n",
       "          1.8358e-01,  3.7814e-01, -6.3743e-01,  1.2234e-01, -1.6112e-01,\n",
       "         -3.0044e-01, -4.3406e-01, -5.0720e-01, -1.1968e+00, -2.0130e-02,\n",
       "         -1.3929e+00, -5.0772e-01,  9.4681e-02, -2.3988e-01, -6.4448e-01,\n",
       "          6.0070e-01,  4.9796e-01, -7.6051e-01, -7.9159e-01, -6.3255e-01,\n",
       "         -1.8188e-01, -2.8149e-01, -6.1385e-01, -9.0548e-01, -9.0872e-02,\n",
       "          1.6240e-01,  6.3300e-01,  5.6919e-01, -1.0053e+00,  4.2668e-01,\n",
       "          3.0496e-01, -5.6392e-01, -6.4523e-01, -2.4225e-01,  7.6478e-01,\n",
       "         -4.7052e-01,  1.7266e-01,  4.2185e-01, -1.2814e+00, -2.8314e-01,\n",
       "         -5.5975e-01,  6.5045e-01,  6.8860e-03,  4.4972e-02, -1.0004e-01,\n",
       "          4.2296e-01, -4.2191e-01, -1.8018e-01,  3.7629e-01,  9.4968e-02,\n",
       "          6.3038e-01, -4.2777e-01,  8.1993e-01, -1.7682e-01, -1.4119e+00,\n",
       "          1.1125e+00,  5.5486e-01,  2.9189e-01, -2.4255e-01, -3.2994e-01,\n",
       "          2.6503e-01, -2.2023e-01, -1.9717e-01,  3.9854e-01, -7.3782e-01,\n",
       "          4.3533e-01, -6.5199e-03,  3.4807e-01,  2.7517e-01,  2.3296e-01,\n",
       "          5.0646e-02,  2.2936e-01,  3.7264e-01, -1.0588e-01, -4.9096e-02,\n",
       "         -1.1893e+00,  2.6967e-01, -1.2429e-01,  4.8982e-01, -6.5274e-01,\n",
       "          1.1337e-01,  9.1142e-01, -3.6291e-01, -1.9792e-01, -6.7120e-02,\n",
       "          2.5185e-01, -2.2889e-02,  5.5547e-01, -9.3180e-02,  4.1501e-01,\n",
       "         -3.7864e-01,  2.8134e-01, -6.5665e-02, -6.7896e-01,  5.1437e-01,\n",
       "         -1.3248e+00,  9.6547e-01,  6.2809e-02, -8.4057e-01,  3.1344e-01,\n",
       "         -1.8533e-02, -5.7860e-01,  4.6965e-01,  5.9905e-01, -1.6480e-02,\n",
       "          7.2556e-01,  5.5830e-02,  3.7092e-01,  3.4050e-01, -6.7803e-01,\n",
       "         -3.6094e-01,  1.0035e+00,  3.1344e-01, -9.4857e-02,  1.0725e+00,\n",
       "         -1.2750e+00, -6.5956e-02, -4.1639e-01, -6.5001e-01,  2.2045e+00,\n",
       "          3.3662e-01,  1.2246e+00, -9.0521e-01,  2.3621e-01,  5.4738e-01,\n",
       "         -6.7577e-01, -1.2572e+00, -6.5907e-01, -1.2754e+00,  7.6876e-01,\n",
       "         -2.7887e-01, -3.6465e-01,  3.5797e-01,  8.7833e-01, -5.6609e-01,\n",
       "         -8.6390e-01, -2.9465e-01, -6.2891e-01, -5.8465e-01,  5.1740e-01])]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flair_embedding_vectors = []\n",
    "\n",
    "for row in features.iterrows():\n",
    "    m1 = row[1]['m1']\n",
    "    m2 = row[1]['m2']\n",
    "    short_path = row[1]['short_path']\n",
    "    \n",
    "    # get the word embedding representation for each word in the shortest path\n",
    "    row_embeddings = []\n",
    "    \n",
    "    for word in short_path:\n",
    "        try:\n",
    "            row_embeddings.append(flair_embeddings[word])\n",
    "        except KeyError as err:\n",
    "            print(err)\n",
    "            row_embeddings.append(np.zeros(vector_len))\n",
    "    \n",
    "    flair_embedding_vectors.append(sum(row_embeddings))\n",
    "    vector_data = {'m1': m1, 'm2': m2, 'short_path_embedding_vector': sum(row_embeddings)}\n",
    "    training_example = pd.Series(vector_data, index=vector_feature_columns)\n",
    "    vector_features = vector_features.append(training_example, ignore_index=True)\n",
    "\n",
    "flair_embedding_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create tuples of the word embedding vectors for plotting purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-1.1571e+00,  2.3111e-01, -1.9308e+00, -1.1682e+00, -7.4470e-01,\n",
       "          1.1951e+00, -4.3329e-01, -3.0150e-01,  7.1854e-01,  5.3736e-01,\n",
       "         -1.7087e-01, -6.7910e-02, -5.5695e-01, -1.9679e-01, -3.5563e-02,\n",
       "         -1.5552e-01, -4.9553e-01,  1.1511e+00, -7.0194e-01,  6.2212e-01,\n",
       "          5.3428e-01,  5.3036e-01,  1.9694e-02,  9.1691e-01, -6.9134e-02,\n",
       "         -2.2981e-01,  2.1040e-02,  1.1885e+00, -7.1146e-01, -1.1373e+00,\n",
       "          7.3750e-01,  1.5989e-01,  2.8375e-02, -5.0487e-01, -1.1745e+00,\n",
       "         -1.0308e+00, -6.5149e-01,  1.4186e-01, -6.0350e-01,  8.0303e-01,\n",
       "         -1.6300e-03, -4.1764e-01, -4.0262e-01,  2.1460e-03, -4.1026e-01,\n",
       "         -7.3068e-01,  8.4265e-01, -3.1099e-01, -5.0911e-01, -7.4222e-01,\n",
       "          5.0225e-01,  6.8844e-01,  5.9872e-01,  5.5705e-02, -2.7957e-01,\n",
       "         -2.9116e-01, -4.7137e-01,  1.6188e-01, -2.0561e-01, -3.8416e-01,\n",
       "          1.1123e-02, -7.6916e-01,  1.4325e+00, -7.4875e-01, -8.6174e-01,\n",
       "         -4.9399e-01, -9.8840e-02,  6.0916e-01, -6.1926e-01,  3.3192e-01,\n",
       "         -1.2810e+00, -4.0659e-01, -2.7177e-02,  1.1945e+00, -3.2305e-01,\n",
       "         -2.7817e-01,  1.9641e-01, -1.1798e+00, -3.4814e-01,  8.1192e-01,\n",
       "          2.9021e-01, -6.6750e-02, -1.0321e-02, -1.7299e-01, -6.8707e-01,\n",
       "         -6.5709e-01,  7.2941e-01,  1.2979e+00, -3.0908e-01, -2.8060e-01,\n",
       "         -5.7759e-01,  1.5237e-01,  3.5665e-01, -4.9849e-01, -5.4589e-02,\n",
       "         -7.7133e-01,  4.5691e-01,  1.4774e+00, -9.5272e-01,  5.3983e-01,\n",
       "          8.6862e-01,  6.0277e-02, -3.1754e-01, -1.2272e-01,  7.0823e-01,\n",
       "          8.7169e-01, -2.0977e-01,  1.2028e+00,  9.2625e-02,  4.4479e-01,\n",
       "         -4.5444e-01,  2.9942e-01,  5.6466e-01,  2.3062e-01,  6.1480e-02,\n",
       "          4.7532e-01,  2.2778e-01, -1.5998e-01, -9.0376e-01, -2.2181e-01,\n",
       "          9.5685e-02,  2.9138e-01,  1.3088e+00,  4.7565e-01, -4.8901e-04,\n",
       "          1.2019e+00,  1.0534e+00,  2.8543e-01, -5.8544e-01,  3.5472e-01,\n",
       "          3.0544e-01, -4.2422e-01,  8.6940e-01,  7.2609e-01,  6.7906e-01,\n",
       "          2.0668e-01, -4.5298e-01,  8.6188e-02,  1.0581e+00, -2.2621e-01,\n",
       "         -7.0036e-01, -3.3699e-01,  9.7917e-01,  1.1307e+00,  3.6630e-01,\n",
       "         -9.4039e-01,  2.0634e-01, -8.7127e-02,  4.5478e-01,  7.1453e-01,\n",
       "          7.0034e-01,  7.1405e-02, -1.9764e-01,  4.1235e-01,  3.7073e-01,\n",
       "         -2.8570e-01, -7.3916e-01,  1.3709e+00,  6.6767e-01,  5.8566e-01,\n",
       "          1.8358e-01,  3.7814e-01, -6.3743e-01,  1.2234e-01, -1.6112e-01,\n",
       "         -3.0044e-01, -4.3406e-01, -5.0720e-01, -1.1968e+00, -2.0130e-02,\n",
       "         -1.3929e+00, -5.0772e-01,  9.4681e-02, -2.3988e-01, -6.4448e-01,\n",
       "          6.0070e-01,  4.9796e-01, -7.6051e-01, -7.9159e-01, -6.3255e-01,\n",
       "         -1.8188e-01, -2.8149e-01, -6.1385e-01, -9.0548e-01, -9.0872e-02,\n",
       "          1.6240e-01,  6.3300e-01,  5.6919e-01, -1.0053e+00,  4.2668e-01,\n",
       "          3.0496e-01, -5.6392e-01, -6.4523e-01, -2.4225e-01,  7.6478e-01,\n",
       "         -4.7052e-01,  1.7266e-01,  4.2185e-01, -1.2814e+00, -2.8314e-01,\n",
       "         -5.5975e-01,  6.5045e-01,  6.8860e-03,  4.4972e-02, -1.0004e-01,\n",
       "          4.2296e-01, -4.2191e-01, -1.8018e-01,  3.7629e-01,  9.4968e-02,\n",
       "          6.3038e-01, -4.2777e-01,  8.1993e-01, -1.7682e-01, -1.4119e+00,\n",
       "          1.1125e+00,  5.5486e-01,  2.9189e-01, -2.4255e-01, -3.2994e-01,\n",
       "          2.6503e-01, -2.2023e-01, -1.9717e-01,  3.9854e-01, -7.3782e-01,\n",
       "          4.3533e-01, -6.5199e-03,  3.4807e-01,  2.7517e-01,  2.3296e-01,\n",
       "          5.0646e-02,  2.2936e-01,  3.7264e-01, -1.0588e-01, -4.9096e-02,\n",
       "         -1.1893e+00,  2.6967e-01, -1.2429e-01,  4.8982e-01, -6.5274e-01,\n",
       "          1.1337e-01,  9.1142e-01, -3.6291e-01, -1.9792e-01, -6.7120e-02,\n",
       "          2.5185e-01, -2.2889e-02,  5.5547e-01, -9.3180e-02,  4.1501e-01,\n",
       "         -3.7864e-01,  2.8134e-01, -6.5665e-02, -6.7896e-01,  5.1437e-01,\n",
       "         -1.3248e+00,  9.6547e-01,  6.2809e-02, -8.4057e-01,  3.1344e-01,\n",
       "         -1.8533e-02, -5.7860e-01,  4.6965e-01,  5.9905e-01, -1.6480e-02,\n",
       "          7.2556e-01,  5.5830e-02,  3.7092e-01,  3.4050e-01, -6.7803e-01,\n",
       "         -3.6094e-01,  1.0035e+00,  3.1344e-01, -9.4857e-02,  1.0725e+00,\n",
       "         -1.2750e+00, -6.5956e-02, -4.1639e-01, -6.5001e-01,  2.2045e+00,\n",
       "          3.3662e-01,  1.2246e+00, -9.0521e-01,  2.3621e-01,  5.4738e-01,\n",
       "         -6.7577e-01, -1.2572e+00, -6.5907e-01, -1.2754e+00,  7.6876e-01,\n",
       "         -2.7887e-01, -3.6465e-01,  3.5797e-01,  8.7833e-01, -5.6609e-01,\n",
       "         -8.6390e-01, -2.9465e-01, -6.2891e-01, -5.8465e-01,  5.1740e-01]),)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuples = ()\n",
    "for vector in flair_embedding_vectors:\n",
    "    if not tuples:\n",
    "        tuples = (vector, )\n",
    "    else:\n",
    "        tuples = tuples + (vector, )\n",
    "\n",
    "tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python\\lib\\site-packages\\sklearn\\decomposition\\pca.py:423: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ = (S ** 2) / (n_samples - 1)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-cb0f24fc9170>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = np.vstack(tuples)\n",
    "pca = PCA(n_components=2)\n",
    "result = pca.fit_transform(X)\n",
    "\n",
    "plt.scatter(result[:, 0], result[:, 1])\n",
    "words = list(path_dict.keys())\n",
    "for i, word in enumerate(words):\n",
    "    plt.annotate(word, xy=(result[i, 0], result[i, 1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "clustering = AgglomerativeClustering().fit(X)\n",
    "clustering.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
