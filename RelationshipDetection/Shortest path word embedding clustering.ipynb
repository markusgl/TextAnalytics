{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shortest path relation extraction with word embeddings\n",
    "Approach:\n",
    "* Locate Named Entities in the sentece\n",
    "* Extract dependency path of the sentence using the spaCy dependy parser\n",
    "* Build an undirected network graph of the dependencies in the sentece\n",
    "* Search for the shortest path between every two entities and assume them as related to be each other\n",
    "* Computer feature vector (word embedding) for shortest path feature\n",
    "* Cluster the entities depending on features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import enum\n",
    "import networkx as nx\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from networkx.exception import NodeNotFound, NetworkXNoPath\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "nlp = spacy.load('de')\n",
    "model = KeyedVectors.load_word2vec_format('../models/german.model', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "relationship_list = ['vater', 'mutter', 'sohn', 'tochter', 'bruder', 'schwester', 'enkel', 'enkelin', 'nichte',\n",
    "                     'neffe', 'onkel', 'tante']\n",
    "me_list = ['ich', 'meine', 'mein', 'meiner', 'meinem', 'meinen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = u'''Herbert ist der Vater von Hans'''\n",
    "#text = u'''Peter und Maria gehen morgen ins Kino'''\n",
    "#text = u'''Herbert sein Sohn und ich gehen heute ins Kino'''\n",
    "# text = u'''Ich gehe mit Johann in den Zoo'''\n",
    "#text = u'''Hans und sein Sohn Hubert gehen in den Zoo.'''\n",
    "text = u'''Hans, welcher der Sohn von Hubert ist, geht mit Peter ins Kino.'''\n",
    "#text = u'''Meine kleine Enkelin Lisa und mein Enkel Lukas fliegen morgen nach London.'''\n",
    "#text = u'''Ich fahre mit meinen Enkeln Lukas und Lisa in den Urlaub.'''\n",
    "#text = u'''Potesters seized several pumping stations, holding 127 Shell workers hostage.'''\n",
    "#text = u'''Troops recently have raided churches, warning ministers to stop preaching.'''\n",
    "multiline_text = u'''Homer und sein Sohn Peter gehen mit Milhouse ins Kino. Ich gehe mit Bart laufen.\n",
    "Meine Enkelin Lisa und mein Enkel Peter fliegen morgen nach London. Ned Flanders ist der Vater von Rod und Todd. \n",
    "Homer fährt mit seiner Tochter Lisa zum See.'''\n",
    "text = multiline_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition\n",
    "choose one of the two below (default=Flair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. spaCy NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['homer',\n",
       " 'sohn bart',\n",
       " 'milhouse',\n",
       " 'bart',\n",
       " 'ned flanders',\n",
       " 'rod',\n",
       " 'todd',\n",
       " 'homer',\n",
       " 'lisa zum see',\n",
       " 'ich',\n",
       " 'meine',\n",
       " 'mein']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities = []\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == 'PER':\n",
    "        entities.append(ent.text.lower())\n",
    "\n",
    "for token in doc:\n",
    "    if token.text.lower() in me_list:\n",
    "        entities.append(token.text.lower())\n",
    "\n",
    "entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Flair NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "def extract_entities(raw_sentence):\n",
    "    entities = []\n",
    "\n",
    "    raw_sentence = re.sub('\\W+', ' ', raw_sentence) # remove non-word characters\n",
    "    sentence = Sentence(raw_sentence)\n",
    "    tagger = SequenceTagger.load('de-ner')\n",
    "    tagger.predict(sentence) # run NER over sentence\n",
    "\n",
    "    # NER spans\n",
    "    print('##> Extracting entities...')\n",
    "    for entity in sentence.get_spans('ner'):\n",
    "        print(entity)\n",
    "        if entity.tag == 'PER':\n",
    "            if len(entity.tokens) > 1:  # replace blanks with underscores if entity spans over multiple words\n",
    "                entities.append(str(entity.text.lower()).replace(' ', '_'))\n",
    "            else:\n",
    "                entities.append(entity.text.lower())\n",
    "\n",
    "    # NER tag for each token\n",
    "    #for token in sentence:\n",
    "    #    ner_tag = token.get_tag('ner')\n",
    "    #    print(f'{token}, {ner_tag}')\n",
    "\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build undirected graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_undirected_graph(sentence, plot=False):\n",
    "    doc = nlp(sentence)\n",
    "    edges = []\n",
    "    for token in doc:\n",
    "        for child in token.children:\n",
    "            edges.append((f'{token.lower_}',\n",
    "                          f'{child.lower_}'))\n",
    "    graph = nx.Graph(edges)\n",
    "    if plot:\n",
    "        plot_graph(graph)\n",
    "        \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(graph):\n",
    "    # nx.draw_networkx(graph, node_size=100, ode_color=range(len(graph)))\n",
    "    pos = nx.spring_layout(graph)  # positions for all nodes\n",
    "    # nodes\n",
    "    nx.draw_networkx_nodes(graph, pos, node_size=200)\n",
    "    # edges\n",
    "    nx.draw_networkx_edges(graph, pos, width=1)\n",
    "    # labels\n",
    "    nx.draw_networkx_labels(graph, pos, font_size=12, font_family='sans-serif')\n",
    "\n",
    "    plt.axis('off')  # disable axis\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shortest Dependency Path\n",
    "Find shortest dependency path between every found two entities in a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##> Extracting entities...\n",
      "PER-span [1]: \"Homer\"\n",
      "PER-span [5]: \"Peter\"\n",
      "PER-span [8]: \"Milhouse\"\n",
      "Entities ['homer', 'peter', 'milhouse']\n",
      "##> Extracting entities...\n",
      "Entities []\n",
      "##> Extracting entities...\n",
      "PER-span [3]: \"Lisa\"\n",
      "PER-span [7]: \"Peter\"\n",
      "LOC-span [11]: \"London\"\n",
      "Entities ['lisa', 'peter']\n",
      "##> Extracting entities...\n",
      "PER-span [1,2]: \"Ned Flanders\"\n",
      "PER-span [7]: \"Rod\"\n",
      "PER-span [9]: \"Todd\"\n",
      "Entities ['ned_flanders', 'rod', 'todd']\n",
      "##> Extracting entities...\n",
      "PER-span [1]: \"Homer\"\n",
      "PER-span [6]: \"Lisa\"\n",
      "Entities ['homer', 'lisa']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'homer-peter': ['und', 'sohn'],\n",
       " 'homer-milhouse': ['gehen', 'mit'],\n",
       " 'peter-milhouse': ['sohn', 'und', 'homer', 'gehen', 'mit'],\n",
       " 'lisa-peter': ['und', 'enkel'],\n",
       " 'ned-rod': ['flanders', 'ist', 'vater', 'von'],\n",
       " 'ned-todd': ['flanders', 'ist', 'vater', 'von', 'rod', 'und'],\n",
       " 'rod-todd': ['und'],\n",
       " 'homer-lisa': ['fährt', 'mit', 'tochter']}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dict = {}\n",
    "\n",
    "for sentence in sent_tokenize(text):\n",
    "    entities = extract_entities(sentence)\n",
    "    print(f'Entities {entities}')\n",
    "    graph = build_undirected_graph(sentence)\n",
    "    \n",
    "    for i, first_entity in enumerate(entities):\n",
    "        first_entity = first_entity.split('_')[0]  # use only first name of multi-word entities\n",
    "        \n",
    "        #for j in range(len(entities)):  # bidirectional relations\n",
    "        for j in range(i+1, len(entities)):  # unidirectional relations\n",
    "            second_entity = entities[j]\n",
    "            second_entity = second_entity.split('_')[0]  # use only first name of multi-word entities\n",
    "            \n",
    "            if not i == j and second_entity not in me_list:        \n",
    "                try:\n",
    "                    shortest_path = nx.shortest_path(graph, source=first_entity, target=second_entity)\n",
    "                    key = first_entity + '-' + second_entity\n",
    "                    #path_dict[key] = shortest_path  # include entities in sp\n",
    "                    path_dict[key] = shortest_path[1:-1]  # exclude entities in sp\n",
    "                except NodeNotFound as err:\n",
    "                    logging.warning(f'Node not found: {err}')\n",
    "                except NetworkXNoPath as err:\n",
    "                    logging.warning(f'No path found: {err}')\n",
    "\n",
    "path_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['m1', 'm2', 'm1_pos', 'm2_pos', 'before_m1', 'after_m2', 'between_words', \n",
    "                   'short_path', 'm1_head', 'm2_head']\n",
    "\n",
    "features = pd.DataFrame(columns=feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homer und sein sohn peter gehen mit milhouse ins kino \n",
      "ich gehe mit bart laufen \n",
      "meine enkelin lisa und mein enkel peter fliegen morgen nach london \n",
      "ned flanders ist der vater von rod und todd \n",
      "homer fährt mit seiner tochter lisa zum see \n"
     ]
    }
   ],
   "source": [
    "features_list = []  # for TF-IDF vectorization\n",
    "#ners = []\n",
    "\n",
    "# check for named entity 'PER' or 'PME' in each sentence\n",
    "#for ner_tuple in ner_tuples:\n",
    "#    if 'I-PER' in ner_tuple:\n",
    "#        ners.append(ner_tuple)\n",
    "#    elif ner_tuple[0].lower() in me_list:\n",
    "#        ners.append((ner_tuple[0], 'PME'))\n",
    "#    elif ner_tuple[0].lower() in relationship_list:\n",
    "#        ners.append((ner_tuple[0], 'SOC'))\n",
    "\n",
    "for sentence in sent_tokenize(text):\n",
    "    sentence = re.sub(r'\\W+', ' ', sentence.lower()) # remove non-word characters\n",
    "    print(sentence)\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    for key, value in path_dict.items():\n",
    "        # extract entities\n",
    "        m1 = key.split('-')[0]\n",
    "        m2 = key.split('-')[1]\n",
    "\n",
    "        short_path = value\n",
    "\n",
    "        # POS tagging and head\n",
    "        for token in doc:\n",
    "            if token.text.lower() == m1:\n",
    "                m1_pos_tag = token.pos_\n",
    "                m1_head = token.head.text\n",
    "                #m1_children = [child for child in token.children]\n",
    "            elif token.text.lower() == m2:\n",
    "                m2_pos_tag = token.pos_\n",
    "                m2_head = token.head.text\n",
    "                #m2_children = [child for child in token.children]\n",
    "\n",
    "        # Dependecy parsing\n",
    "        #dep_path = []\n",
    "        #for chunk in doc.noun_chunks:\n",
    "        #    if chunk.root.text.lower() == m1 or chunk.root.text.lower() == m2:\n",
    "        #        dep_path.append([chunk.root.text, chunk.root.dep_, chunk.root.head.text])  \n",
    "\n",
    "        # Between words\n",
    "        start_position_m1 = sentence.find(m1)\n",
    "        start_position_m2 = sentence.find(m2)\n",
    "\n",
    "        # verify if the words were found in the sentence\n",
    "        if not start_position_m1 == -1 and not start_position_m2 == -1:\n",
    "            start_position_between = start_position_m1 + len(m1) + 1\n",
    "            end_position_between = start_position_m2\n",
    "\n",
    "            between = sentence[start_position_between:end_position_between]\n",
    "            between_words = []\n",
    "            for word in word_tokenize(between):\n",
    "                between_words.append(word)\n",
    "\n",
    "            beforeM1 = sentence[:start_position_m1 - 1]\n",
    "            afterM2 = sentence[start_position_m2 + len(m2):]\n",
    "\n",
    "            beforeM1_list = word_tokenize(beforeM1)\n",
    "            afterM2_list = word_tokenize(afterM2)\n",
    "\n",
    "            data = {'m1': m1, 'm2': m2, 'm1_pos': m1_pos_tag, 'm2_pos': m2_pos_tag,\n",
    "                    'before_m1': beforeM1_list, 'after_m2': afterM2_list,\n",
    "                    'between_words': between_words, 'short_path': short_path,\n",
    "                     'm1_head': m1_head, 'm2_head': m2_head}\n",
    "\n",
    "            training_example = pd.Series(data, index=feature_columns)\n",
    "            features = features.append(training_example, ignore_index=True)\n",
    "            #context = [beforeM1, between, afterM2]\n",
    "            #features_list.append(context)\n",
    "\n",
    "#features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m1</th>\n",
       "      <th>m2</th>\n",
       "      <th>m1_pos</th>\n",
       "      <th>m2_pos</th>\n",
       "      <th>before_m1</th>\n",
       "      <th>after_m2</th>\n",
       "      <th>between_words</th>\n",
       "      <th>short_path</th>\n",
       "      <th>m1_head</th>\n",
       "      <th>m2_head</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>homer</td>\n",
       "      <td>peter</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>[homer, und, sein, sohn, peter, gehen, mit, mi...</td>\n",
       "      <td>[gehen, mit, milhouse, ins, kino]</td>\n",
       "      <td>[und, sein, sohn]</td>\n",
       "      <td>[und, sohn]</td>\n",
       "      <td>gehen</td>\n",
       "      <td>gehen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>homer</td>\n",
       "      <td>milhouse</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>[homer, und, sein, sohn, peter, gehen, mit, mi...</td>\n",
       "      <td>[ins, kino]</td>\n",
       "      <td>[und, sein, sohn, peter, gehen, mit]</td>\n",
       "      <td>[gehen, mit]</td>\n",
       "      <td>gehen</td>\n",
       "      <td>mit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>peter</td>\n",
       "      <td>milhouse</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>[homer, und, sein, sohn]</td>\n",
       "      <td>[ins, kino]</td>\n",
       "      <td>[gehen, mit]</td>\n",
       "      <td>[sohn, und, homer, gehen, mit]</td>\n",
       "      <td>gehen</td>\n",
       "      <td>mit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lisa</td>\n",
       "      <td>peter</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>[meine, enkelin]</td>\n",
       "      <td>[fliegen, morgen, nach, london]</td>\n",
       "      <td>[und, mein, enkel]</td>\n",
       "      <td>[und, enkel]</td>\n",
       "      <td>meine</td>\n",
       "      <td>und</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ned</td>\n",
       "      <td>rod</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>[ned, flanders, ist, der, vater, von, rod, und...</td>\n",
       "      <td>[und, todd]</td>\n",
       "      <td>[flanders, ist, der, vater, von]</td>\n",
       "      <td>[flanders, ist, vater, von]</td>\n",
       "      <td>flanders</td>\n",
       "      <td>von</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ned</td>\n",
       "      <td>todd</td>\n",
       "      <td>X</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>[ned, flanders, ist, der, vater, von, rod, und...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[flanders, ist, der, vater, von, rod, und]</td>\n",
       "      <td>[flanders, ist, vater, von, rod, und]</td>\n",
       "      <td>flanders</td>\n",
       "      <td>und</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rod</td>\n",
       "      <td>todd</td>\n",
       "      <td>X</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>[ned, flanders, ist, der, vater, von]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[und]</td>\n",
       "      <td>[und]</td>\n",
       "      <td>von</td>\n",
       "      <td>und</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>homer</td>\n",
       "      <td>lisa</td>\n",
       "      <td>ADV</td>\n",
       "      <td>X</td>\n",
       "      <td>[homer, fährt, mit, seiner, tochter, lisa, zum...</td>\n",
       "      <td>[zum, see]</td>\n",
       "      <td>[fährt, mit, seiner, tochter]</td>\n",
       "      <td>[fährt, mit, tochter]</td>\n",
       "      <td>fährt</td>\n",
       "      <td>mit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      m1        m2 m1_pos m2_pos  \\\n",
       "0  homer     peter    ADJ    ADJ   \n",
       "1  homer  milhouse    ADJ    ADJ   \n",
       "2  peter  milhouse    ADJ    ADJ   \n",
       "3   lisa     peter   VERB    ADJ   \n",
       "4    ned       rod      X      X   \n",
       "5    ned      todd      X    ADJ   \n",
       "6    rod      todd      X    ADJ   \n",
       "7  homer      lisa    ADV      X   \n",
       "\n",
       "                                           before_m1  \\\n",
       "0  [homer, und, sein, sohn, peter, gehen, mit, mi...   \n",
       "1  [homer, und, sein, sohn, peter, gehen, mit, mi...   \n",
       "2                           [homer, und, sein, sohn]   \n",
       "3                                   [meine, enkelin]   \n",
       "4  [ned, flanders, ist, der, vater, von, rod, und...   \n",
       "5  [ned, flanders, ist, der, vater, von, rod, und...   \n",
       "6              [ned, flanders, ist, der, vater, von]   \n",
       "7  [homer, fährt, mit, seiner, tochter, lisa, zum...   \n",
       "\n",
       "                            after_m2  \\\n",
       "0  [gehen, mit, milhouse, ins, kino]   \n",
       "1                        [ins, kino]   \n",
       "2                        [ins, kino]   \n",
       "3    [fliegen, morgen, nach, london]   \n",
       "4                        [und, todd]   \n",
       "5                                 []   \n",
       "6                                 []   \n",
       "7                         [zum, see]   \n",
       "\n",
       "                                between_words  \\\n",
       "0                           [und, sein, sohn]   \n",
       "1        [und, sein, sohn, peter, gehen, mit]   \n",
       "2                                [gehen, mit]   \n",
       "3                          [und, mein, enkel]   \n",
       "4            [flanders, ist, der, vater, von]   \n",
       "5  [flanders, ist, der, vater, von, rod, und]   \n",
       "6                                       [und]   \n",
       "7               [fährt, mit, seiner, tochter]   \n",
       "\n",
       "                              short_path   m1_head m2_head  \n",
       "0                            [und, sohn]     gehen   gehen  \n",
       "1                           [gehen, mit]     gehen     mit  \n",
       "2         [sohn, und, homer, gehen, mit]     gehen     mit  \n",
       "3                           [und, enkel]     meine     und  \n",
       "4            [flanders, ist, vater, von]  flanders     von  \n",
       "5  [flanders, ist, vater, von, rod, und]  flanders     und  \n",
       "6                                  [und]       von     und  \n",
       "7                  [fährt, mit, tochter]     fährt     mit  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vector_feature_columns = ['m1', 'm2', 'short_path_vector', 'm1_head', 'm2_head']\n",
    "vector_features = pd.DataFrame(columns=vector_feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embeddings of the words inside the shortest path and sum them into a single vector\n",
    "* Two Representations: GermanWordEmbeddings and Flair Word Embeddings\n",
    "Choose one of the two below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. GermanWordEmbeddings https://github.com/devmount/GermanWordEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\program files\\python\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"word 'homer' not in vocabulary\"\n",
      "\"word 'mit' not in vocabulary\"\n",
      "\"word 'milhouse' not in vocabulary\"\n",
      "\"word 'flanders' not in vocabulary\"\n",
      "\"word 'ist' not in vocabulary\"\n",
      "\"word 'von' not in vocabulary\"\n",
      "\"word 'flanders' not in vocabulary\"\n",
      "\"word 'ist' not in vocabulary\"\n",
      "\"word 'von' not in vocabulary\"\n",
      "\"word 'und' not in vocabulary\"\n",
      "\"word 'todd' not in vocabulary\"\n",
      "\"word 'und' not in vocabulary\"\n",
      "\"word 'todd' not in vocabulary\"\n",
      "\"word 'homer' not in vocabulary\"\n",
      "\"word 'fährt' not in vocabulary\"\n",
      "\"word 'mit' not in vocabulary\"\n",
      "\"word 'tochter' not in vocabulary\"\n",
      "\"word 'lisa' not in vocabulary\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m1</th>\n",
       "      <th>m2</th>\n",
       "      <th>short_path_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>homer</td>\n",
       "      <td>milhouse</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ned</td>\n",
       "      <td>rod</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ned</td>\n",
       "      <td>todd</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rod</td>\n",
       "      <td>todd</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>homer</td>\n",
       "      <td>lisa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      m1        m2 short_path_vector\n",
       "0  homer  milhouse               NaN\n",
       "1    ned       rod               NaN\n",
       "2    ned      todd               NaN\n",
       "3    rod      todd               NaN\n",
       "4  homer      lisa               NaN"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_vectors = []\n",
    "# get vector length\n",
    "vector_len = len(model.wv['hallo'])\n",
    "\n",
    "for row in features.iterrows():\n",
    "    m1 = row[1]['m1']\n",
    "    m2 = row[1]['m2']\n",
    "    short_path = row[1]['short_path']\n",
    "    \n",
    "    # get the word embedding representation for each word in the shortest path\n",
    "    #row_embeddings = np.empty(len(short_path))\n",
    "    row_embeddings = []\n",
    "    \n",
    "    for word in short_path:\n",
    "        try:\n",
    "            row_embeddings.append(model.wv[word])\n",
    "        except KeyError as err:\n",
    "            print(err)\n",
    "            row_embeddings.append(np.zeros(vector_len))\n",
    "    \n",
    "    #print(sum(row_embeddings))\n",
    "    embedding_vectors.append(sum(row_embeddings))\n",
    "    vector_data = {'m1': m1, 'm2': m2, 'short_path_embedding_vector': sum(row_embeddings)}\n",
    "    training_example = pd.Series(vector_data, index=vector_feature_columns)\n",
    "    vector_features = vector_features.append(training_example, ignore_index=True)\n",
    "\n",
    "# summarize vectors    \n",
    "#row_embeddings.sum()\n",
    "vector_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Flair Word Embeddings  https://github.com/zalandoresearch/flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence, Token\n",
    "from flair.embeddings import WordEmbeddings\n",
    "\n",
    "flair_embeddings = {}\n",
    "for sentence in sent_tokenize(text):\n",
    "    sentence = re.sub(r'\\W', ' ', sentence)\n",
    "    sentence = re.sub(r'\\s{2,}', ' ', sentence)    \n",
    "    \n",
    "    sentence = Sentence(sentence.lower())\n",
    "    glove_embedding = WordEmbeddings('de')\n",
    "    #glove_embedding = WordEmbeddings('de-crawl')\n",
    "    glove_embedding.embed(sentence)\n",
    "    \n",
    "    for token in sentence:\n",
    "        flair_embeddings[token.text] = token.embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('german'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop word found: und\n",
      "stop word found: mit\n",
      "stop word found: und\n",
      "stop word found: mit\n",
      "stop word found: und\n",
      "stop word found: ist\n",
      "stop word found: von\n",
      "stop word found: ist\n",
      "stop word found: von\n",
      "stop word found: und\n",
      "stop word found: und\n",
      "stop word found: mit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['homer-peter',\n",
       " 'homer-milhouse',\n",
       " 'peter-milhouse',\n",
       " 'lisa-peter',\n",
       " 'ned-rod',\n",
       " 'ned-todd',\n",
       " 'homer-lisa']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flair_embedding_vectors = []\n",
    "labels = []\n",
    "for row in features.iterrows():\n",
    "    m1 = row[1]['m1']\n",
    "    m2 = row[1]['m2']\n",
    "    short_path = row[1]['short_path']\n",
    "    m1_head = row[1]['m1_head']\n",
    "    m2_hed = row[1]['m2_head']\n",
    "    \n",
    "    # get the word embedding for each word in the shortest path\n",
    "    row_embeddings = []\n",
    "    \n",
    "    for word in short_path:\n",
    "        if word not in stop_words:  # exclude stop words\n",
    "            try:\n",
    "                #row_embeddings.append(flair_embeddings[word])\n",
    "                # weight embedding higher if it contains a relation\n",
    "                if word.lower() in relationship_list:\n",
    "                    row_embeddings.append(flair_embeddings[word]*1.8)\n",
    "                else:\n",
    "                    row_embeddings.append(flair_embeddings[word])\n",
    "            except KeyError as err:\n",
    "                print(err)\n",
    "                row_embeddings.append(np.zeros(vector_len))\n",
    "        else:\n",
    "            print(f'stop word found: {word}')\n",
    "    \n",
    "    # append word embeddings for head words\n",
    "    \"\"\"\n",
    "    if m1_head:\n",
    "        try:\n",
    "            row_embeddings.append(flair_embeddings[m1_head])\n",
    "        except KeyError as err:\n",
    "            print(err)\n",
    "    if m2_head:\n",
    "        try:\n",
    "            row_embeddings.append(flair_embeddings[m2_head])\n",
    "        except KeyError as err:\n",
    "            print(err)\n",
    "    \"\"\"\n",
    "    \n",
    "    if row_embeddings:\n",
    "        flair_embedding_vectors.append(sum(row_embeddings))\n",
    "        labels.append(m1+'-'+m2)\n",
    "        #vector_data = {'m1': m1, 'm2': m2, 'short_path_embedding_vector': sum(row_embeddings)}\n",
    "        #training_example = pd.Series(vector_data, index=vector_feature_columns)\n",
    "        #vector_features = vector_features.append(training_example, ignore_index=True)\n",
    "\n",
    "#vector_features\n",
    "#flair_embedding_vectors\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create tuples of the word vector representations for plotting purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tuples = ()\n",
    "for vector in flair_embedding_vectors:\n",
    "    if not tuples:\n",
    "        tuples = (vector, )\n",
    "    else:\n",
    "        tuples = tuples + (vector, )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot summarized word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 7 is out of bounds for axis 0 with size 7",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-144-cb0f24fc9170>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 7 is out of bounds for axis 0 with size 7"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = np.vstack(tuples)\n",
    "pca = PCA(n_components=2)\n",
    "result = pca.fit_transform(X)\n",
    "\n",
    "plt.scatter(result[:, 0], result[:, 1])\n",
    "words = list(path_dict.keys())\n",
    "for i, word in enumerate(words):\n",
    "    plt.annotate(word, xy=(result[i, 0], result[i, 1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dendrogram for choosing the right number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-130-423fdc35cb0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mdistance_sort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'descending'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             show_leaf_counts=True)\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python\\lib\\site-packages\\scipy\\cluster\\hierarchy.py\u001b[0m in \u001b[0;36mdendrogram\u001b[1;34m(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color)\u001b[0m\n\u001b[0;32m   2494\u001b[0m         \u001b[0mcontraction_marks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcontraction_marks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2495\u001b[0m         \u001b[0mlink_color_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlink_color_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2496\u001b[1;33m         above_threshold_color=above_threshold_color)\n\u001b[0m\u001b[0;32m   2497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2498\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_plot\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python\\lib\\site-packages\\scipy\\cluster\\hierarchy.py\u001b[0m in \u001b[0;36m_dendrogram_calculate_info\u001b[1;34m(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, i, iv, ivl, n, icoord_list, dcoord_list, lvs, mhr, current_color, color_list, currently_below_threshold, leaf_label_func, level, contraction_marks, link_color_func, above_threshold_color)\u001b[0m\n\u001b[0;32m   2747\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontraction_marks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcontraction_marks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2748\u001b[0m             \u001b[0mlink_color_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlink_color_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2749\u001b[1;33m             above_threshold_color=above_threshold_color)\n\u001b[0m\u001b[0;32m   2750\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2751\u001b[0m     \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python\\lib\\site-packages\\scipy\\cluster\\hierarchy.py\u001b[0m in \u001b[0;36m_dendrogram_calculate_info\u001b[1;34m(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, i, iv, ivl, n, icoord_list, dcoord_list, lvs, mhr, current_color, color_list, currently_below_threshold, leaf_label_func, level, contraction_marks, link_color_func, above_threshold_color)\u001b[0m\n\u001b[0;32m   2747\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontraction_marks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcontraction_marks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2748\u001b[0m             \u001b[0mlink_color_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlink_color_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2749\u001b[1;33m             above_threshold_color=above_threshold_color)\n\u001b[0m\u001b[0;32m   2750\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2751\u001b[0m     \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python\\lib\\site-packages\\scipy\\cluster\\hierarchy.py\u001b[0m in \u001b[0;36m_dendrogram_calculate_info\u001b[1;34m(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, i, iv, ivl, n, icoord_list, dcoord_list, lvs, mhr, current_color, color_list, currently_below_threshold, leaf_label_func, level, contraction_marks, link_color_func, above_threshold_color)\u001b[0m\n\u001b[0;32m   2659\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2660\u001b[0m         _append_singleton_leaf_node(Z, p, n, level, lvs, ivl,\n\u001b[1;32m-> 2661\u001b[1;33m                                     leaf_label_func, i, labels)\n\u001b[0m\u001b[0;32m   2662\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0miv\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m5.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2663\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python\\lib\\site-packages\\scipy\\cluster\\hierarchy.py\u001b[0m in \u001b[0;36m_append_singleton_leaf_node\u001b[1;34m(Z, p, n, level, lvs, ivl, leaf_label_func, i, labels)\u001b[0m\n\u001b[0;32m   2529\u001b[0m             \u001b[1;31m# for the leaf nodes, use it.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2530\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2531\u001b[1;33m                 \u001b[0mivl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2532\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2533\u001b[0m                 \u001b[1;31m# Otherwise, use the id as the label for the leaf.x\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage  \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "linked = linkage(X, 'single')\n",
    "\n",
    "#labelList = range(1, 11)\n",
    "\n",
    "plt.figure(figsize=(10, 7))  \n",
    "dendrogram(linked,  \n",
    "            orientation='top',\n",
    "            labels=words,\n",
    "            distance_sort='descending',\n",
    "            show_leaf_counts=True)\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define number of clusters depending on the dendogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agglomerative Hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4, 5, 0, 2, 3, 1], dtype=int64)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "#labels = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
    "labels = words\n",
    "agglo_clustering = AgglomerativeClustering(linkage='ward', affinity='euclidean', n_clusters=n)\n",
    "agglo_clustering.fit(X, labels)\n",
    "\n",
    "agglo_clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1f64cc331d0>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[:,0],X[:,1], c=agglo_clustering.labels_, cmap='rainbow')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 2, 1, 0, 1, 1, 3, 0, 1, 1, 0, 0, 0, 2, 2, 0, 1, 3, 3,\n",
       "       2, 1, 0, 2, 2, 1, 0, 0, 1, 3, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0, 2, 2,\n",
       "       3, 2, 2, 0, 0, 2, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 3, 2, 0, 2,\n",
       "       1, 1, 0, 0, 0, 2, 0, 3, 0, 1, 1, 1, 1, 2, 0, 0, 2, 2, 2, 0, 1, 3,\n",
       "       0, 2, 2, 2, 2, 0, 1, 2, 3, 1, 0, 0, 2, 1, 2, 1, 3, 1, 2, 0, 2, 2,\n",
       "       2, 3, 1, 0, 3, 2, 1, 2, 0, 1, 2, 2, 1, 3, 2, 3, 2, 2, 1, 2, 2, 1,\n",
       "       2, 1, 2, 1, 2, 3, 1, 2, 0, 2, 2, 3, 0, 0, 1, 1, 0, 1, 1, 2, 2, 1,\n",
       "       2, 2, 0, 3, 3, 1, 0, 1, 2, 1, 0, 1, 0, 2, 0, 2, 0, 0, 2, 2, 1, 1,\n",
       "       1, 0, 1, 0, 2, 1, 2, 0, 3, 1, 0, 2, 2, 2, 1, 1, 2, 2, 3, 2, 0, 1,\n",
       "       0, 2, 2, 2, 3, 2, 2, 3, 2, 0, 1, 2, 1, 2, 1, 1, 0, 3, 0, 0, 1, 1,\n",
       "       0, 2, 2, 2, 0, 1, 1, 2, 1, 3, 2, 2, 2, 2, 0, 0, 0, 0, 1, 2, 2, 2,\n",
       "       1, 2, 2, 2, 0, 2, 0, 3, 2, 1, 0, 2, 2, 0, 3, 2, 2, 2, 2, 2, 2, 3,\n",
       "       2, 2, 2, 1, 2, 0, 2, 1, 3, 0, 1, 0, 1, 0, 0, 3, 1, 3, 1, 1, 3, 0,\n",
       "       0, 0, 0, 2, 2, 2, 1, 3, 0, 0, 2, 2, 1, 3], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agglo_clustering.fit_predict(np.vstack(tuples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
