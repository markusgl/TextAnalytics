{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shortest path relation extraction with word embeddings\n",
    "Approach:\n",
    "1. Search for Named Entities of type PERSON in sentence\n",
    "2. Build undirected graph of the dependecy path\n",
    "3. Search shortest path between each entity tuple\n",
    "4. Store words appearing on shortest path\n",
    "5. Get word embedding representation for each word on the shortest path (SP vectors)\n",
    "6. Sum SP vectors to a single vector\n",
    "7. Cluster vectors using hierarchical agglomerative clustering (HAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import enum\n",
    "import networkx as nx\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from networkx.exception import NodeNotFound, NetworkXNoPath\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Self-created data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (DE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = 'DE'\n",
    "utterance1 = u'''Herbert ist der Vater von Hans'''\n",
    "utterance2 = u'''Peter und Maria gehen morgen ins Kino'''\n",
    "utterance3 = u'''Herbert sein Sohn und ich gehen heute ins Kino'''\n",
    "utterance4 = u'''Ich gehe mit Johann in den Zoo'''\n",
    "utterance5 = u'''Hans und sein Sohn Hubert gehen in den Zoo.'''\n",
    "utterance6 = u'''Hans, welcher der Sohn von Hubert ist, geht mit Peter ins Kino.'''\n",
    "utterance7 = u'''Meine kleine Enkelin Lisa und mein Enkel Lukas fliegen morgen nach London.'''\n",
    "utterance8 = u'''Ich fahre mit meinen Enkeln Lukas und Lisa in den Urlaub.'''\n",
    "utterance9 = u'''Potesters seized several pumping stations, holding 127 Shell workers hostage.'''\n",
    "utterance10 = u'''Troops recently have raided churches, warning ministers to stop preaching.'''\n",
    "multi_utterances = u'''Homer und sein Sohn Peter gehen mit Milhouse ins Kino. Ich gehe mit Bart laufen.\n",
    "Meine Enkelin Lisa und mein Enkel Peter fliegen morgen nach London. Ned Flanders ist der Vater von Rod und Todd. \n",
    "Homer fährt mit seiner Tochter Lisa zum See. Homer fährt mit seiner Tochter Lisa zum See. Ich habe 3 Geschwister. \n",
    "Ich habe einen Bruder.'''\n",
    "\n",
    "text = multi_utterances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (EN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = 'EN'\n",
    "utterance1 = u'''my boyfriend and i are moving into an apartment together next week. i've a children and a dogs.\n",
    "                my sister Lindsey lives in New York. She works as a journalist. \n",
    "                i love going to the park with my three children and my wife.'''\n",
    "utterance2 = u'''My sister Lindsey lives in New York.'''\n",
    "utterance3 = u'''my father is an electrician. my father is a farmer.'''\n",
    "utterance4 = u'''my boyfriend and i are moving into an apartment together next week.'''\n",
    "utterance5 = u'''i've a children and a dogs.'''\n",
    "utterance6 = u'''Hi! You're Homer's sister-in-law, right? I remember you, but I don't remember you being so beau'''\n",
    "utterance7 = u'''Barack Obama is married to Michele Obama.'''\n",
    "utterance8 = u'''I have two children. My daughter lives in Berlin, my son is studying in Munich.'''\n",
    "utterance9 = u'''Peter is the fater of Tom.'''\n",
    "utterance10 = u'''Peter, Tom's father, will pick us up today.'''\n",
    "utterance11 = u'''My daughter Lisa is moving to London next month.'''\n",
    "\n",
    "text = utterance11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Conversation Data from ConvAI coropus (EN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First have a look at the data set and create a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'sender_class'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-abefd2946da3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mdialog\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dialog'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0msender\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdialog\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sender_class'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdialog\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'sender_class'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "with open('data/convai/export_2018-07-04_train.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "df_columns = ['sender', 'text']\n",
    "df = pd.DataFrame(columns=df_columns)\n",
    "\n",
    "for row in data:\n",
    "    for dialog in row['dialog']:\n",
    "        sender = dialog['sender_class']\n",
    "        text = dialog['text']\n",
    "\n",
    "        data = {'sender': sender, 'text': text}\n",
    "        df = df.append(data, ignore_index=True)\n",
    "\n",
    "df[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract human dialogs and store to text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lang = 'EN'\n",
    "\n",
    "human_conv = df.loc[df['sender'] == 'Human']\n",
    "\n",
    "corpus = ''\n",
    "for row in human_conv['text']:\n",
    "    corpus += row.replace('\\n', '') + ' '\n",
    "  \n",
    "text = corpus[:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Simpsons conversations (EN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = 'EN'\n",
    "with open('data/simpsons_conversations.txt', 'r', encoding='utf-8') as f:\n",
    "    data = f.read()\n",
    "    data = data.replace('\\n', ' ')\n",
    "    \n",
    "corpus = data[5000:10000]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Book of Genesis (EN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = 'EN'\n",
    "with open('data/NETBible_Genesis.txt', 'r', encoding='utf-8') as f:\n",
    "    data = f.read()\n",
    "    \n",
    "corpus = data[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Robinson Crusoe (DE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Was für andere Gründe, sagte er, als die bloße Vorliebe für ein unstetes Leben, können dich bewegen, Vaterhaus und Heimat verlassen zu wollen, wo du dein gutes Unterkommen hast und bei Fleiß und Ausdauer in ruhigem und behaglichem Leben dein Glück machen kannst.\\nSie ist weder dem Elend und der Mühsal der nur von Händearbeit lebenden Menschenklasse ausgesetzt, noch wird sie von dem Hochmuth, der Ueppigkeit, dem Ehrgeiz und dem Neid, die in den höheren Sphären der Menschenwelt zu Hause sind, heimgesucht. Am besten, fügte er hinzu, kannst du die Glückseligkeit des Mittelstandes daraus erkennen, daß er von Allen, die ihm nicht angehören, beneidet wird.\\nAuch der Weise bezeugt, daß jener Stand der des wahren Glückes ist, indem er betet: Armuth und Reichthum gib mir nicht.\\nHabe nur darauf Acht, fuhr mein Vater fort, so wirst du finden, daß das Elend der Menschheit zumeist an die höheren und niederen Schichten der Gesellschaft vertheilt ist.\\nDieser Weg führt vielmehr in gelassener Behaglichkei'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang = 'DE'\n",
    "with open('data/Robinson_Crusoe_conversations.txt', 'r', encoding='utf-8') as f:\n",
    "    data = f.read()\n",
    "    \n",
    "corpus = data[:1000]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Winnetou Band 1 (DE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeffDiese Zurückhaltung schien ihm aber keineswegs lieb zu sein; ich erinnere mich noch heut des zornigen Gesichtes, welches er mir eines Abends, als ich zu ihm kam, zeigte, und des Tones, in welchem er mich empfing, ohne auf mein ›good evening‹ zu antworten: Wo habt Ihr denn gestern gesteckt, Sir? Zu Hause. Und vorgestern? Auch zu Hause. Macht mir doch nichts weis! Es ist wahr, Mr. Henry. Pshaw!\\nSolche grüne Vögel, wie Ihr einer seid, bleiben nicht im Neste hocken; die stecken die Schnäbel überall hin, nur da nicht, wo sie hingehören! Und wo gehöre ich hin, wenn es Euch beliebt, es mir zu sagen? Hierher zu mir, verstanden!\\nHabe Euch schon lange einmal nach etwas fragen wollen. Warum habt Ihr es nicht getan? Weil ich nicht wollte.\\nHört Ihr es? Und wann wollt Ihr denn? Heute vielleicht. So fragt getrost nur zu, forderte ich ihn auf, indem ich mich hoch auf die Schraubenbank setzte, an welcher er arbeitete.\\nAls ob ich so ein Greenhorn, wie Ihr seid, erst um Erlaubnis fragen müßte, wenn ich mit ihm reden will! Greenhorn? antwortete ich, die Stirn in Falten ziehend, denn ich fühlte mich bedeutend verletzt.\\nIch will annehmen, Mr. Henry, daß dieses Wort Euch ohne Absicht und nur so herausgefahren ist! Bildet Euch doch nichts ein, Sir!\\nIhr könnt ja nicht einmal schießen! Er sagte dies in einem außerordentlich verächtlichen Tone und mit einer solchen Bestimmtheit, als ob er seiner Sache förmlich sicher sei.\\nHm! antwortete ich lächelnd.\\nIst dies vielleicht die Frage, welche Ihr mir vorlegen wolltet? Ja, die ist es.\\nNun antwortet doch einmal! Gebt mir ein gutes Gewehr in die Hand, so will ich antworten, eher nicht. Da legte er den Büchsenlauf, an welchem er schraubte, weg, stand auf, trat nahe an mich heran, fixierte mich mit verwunderten Augen und rief aus: Ein Gewehr in die Hand, Sir?\\nMeine Gewehre kommen nur in solche Hände, in denen ich mit ihnen Ehre einlegen kann! Solche hab ich, nickte ich ihm zu.\\nKönnte mich wirklich wild machen mit seiner Dreistigkeit! Ich ließ ihn gewähren, denn ich kannte ihn, zog eine Zigarre hervor und brannte sie an.\\nHabt Ihr denn jemals ein Gewehr in der Hand gehabt? Ich denke. Wann? Schon längst und oft. Auch angelegt und abgedrückt? Ja. Und getroffen? Natürlich! Da ließ er den Lauf, den er geprüft hatte, rasch sinken, sah mich wieder an und meinte: Ja, getroffen, natürlich, aber was? Das Ziel, ganz selbstverständlich. Was?\\nWollt Ihr mir das im Ernste aufbinden? Behaupten, aber nicht aufbinden; es ist wahr. Hol Euch der Teufel, Sir!\\nEs ist ein Bärentöter, der beste, den ich jemals in den Händen gehabt habe. Ich ging hin, langte die Büchse herab und legte sie an.\\nHalloo! rief er aus, indem er aufsprang.\\nBesitzt Ihr denn eine solche Körperkraft? Anstatt der Antwort nahm ich ihn unten bei der zugeknöpften Jacke und bei dem Hosenbund und hob ihn mit dem rechten Arm empor.\\nThunder-storm! schrie er auf.\\nIhr seid ja noch weit kräftiger als mein Bill. Euer Bill?\\nWer ist das? Er war mein Sohn, der lassen wir das!\\nIhr seid ihm ähnlich von Gestalt, habt beinahe dieselben Augen und auch denselben Zug um den Mund; darum bin ich Euch na, das geht Euch ja doch nichts an! Der Ausdruck tiefer Trauer hatte sich über sein Gesicht gebreitet; er fuhr mit der Hand über dasselbe und fuhr dann in munterem Tone fort: Aber, Sir, bei Eurer Muskelkraft ist es wirklich jammerschade, daß Ihr Euch so auf die Bücher geworfen habt.\\nHättet Euch körperlich üben sollen! Habe ich auch. Wirklich? Ja. Boxen? Wird drüben bei uns nicht getrieben.\\nAber im Turnen und Ringen mache ich mit. Reiten? Ja. Fechten? Habe ich Unterricht erteilt. Mann, schneidet nicht auf! Wollt Ihr es versuchen? Danke; habe genug von vorhin!\\nSetzt Euch wieder nieder! Er kehrte zu seiner Schraubenbank zurück, und ich tat dasselbe.\\nPlötzlich sah er von der Arbeit auf und fragte: Habt Ihr Mathematik getrieben? War eine meiner Lieblingswissenschaften. Arithmetik, Geometrie? Natürlich. Feldmesserei? Sogar außerordentlich gern.\\nBin sehr oft, ohne daß ich es notwendig hatte, mit dem Theodolit draußen herumgelaufen. Und könnt messen, wirklich messen? Ja.\\nIch habe mich sowohl an Horizontal-, als auch an Höhenmessungen oft beteiligt, obgleich ich nicht behaupten will, daß ich mich als ausgelernten Geodäten betrachte. Well sehr gut, sehr gut! Warum fragt Ihr danach, Mr. Henry? Weil ich eine Ursache dazu habe.\\nMuß vorher wissen hm, ja, muß vorher wissen, ob Ihr schießen könnt. So stellt mich auf die Probe! Werde es auch tun; ja, werde es tun; darauf könnt Ihr Euch verlassen.\\nWann beginnt Ihr morgen früh den Unterricht? Um acht Uhr. So kommt um sechs zu mir.\\nWollen hinauf auf den Schießstand gehen, wo ich meine Gewehre einschieße. Warum so früh? Weil ich nicht länger warten will.\\nJetzt genug davon, habe Anderes zu tun, was weit, weit wichtiger ist. Er schien mit dem Gewehrlaufe fertig zu sein und nahm aus einem Kasten ein polygones Eisenstück, dessen Ecken er abzufeilen begann.\\nIch war neugierig, zu erfahren, warum; darum fragte ich ihn: Soll das auch ein Gewehrteil '"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang = 'DE'\n",
    "with open('data/Winnetou_Band1_conversations.txt', 'r', encoding='utf-8') as f:\n",
    "    data = f.read()\n",
    "    \n",
    "corpus = data[:5000]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set language settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "if lang == 'DE':\n",
    "    nlp = spacy.load('de') # for various nlp tasks (pos, ner, dep-path etc.)\n",
    "    flair_ner_tagger_lang = 'de-ner'\n",
    "    stop_words = set(stopwords.words('german'))\n",
    "    stemmer_lang = 'german'\n",
    "    \n",
    "    relationship_list = ['vater', 'mutter', 'papa', 'papi', 'mama', 'mami', 'sohn', 'tochter', 'bruder', 'schwester', \n",
    "                         'enkel', 'enkelin', 'nichte', 'neffe', 'großvater', 'großmutter', 'opa', 'opa', \n",
    "                         'onkel', 'tante', 'cousin', 'cousine', 'schwager', 'schwägerin', 'mann', 'frau', 'ehemann', 'ehefrau']\n",
    "    me_list = ['ich', 'mein', 'meine']\n",
    "    \n",
    "    grammar = r\"\"\"\n",
    "            PP: {<PRON><AUX><DET><ADJ>?<NOUN>}\n",
    "            NP: {<DET><ADJ>?<NOUN><PROPN>*}            \n",
    "            REL: {<PP>|<NP>}\"\"\"\n",
    "    \n",
    "elif lang == 'EN':\n",
    "    nlp = spacy.load('en')\n",
    "    flair_ner_tagger_lang = 'ner'\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stemmer_lang = 'english'\n",
    "    \n",
    "    relationship_list = ['father', 'mother', 'dad', 'daddy', 'mom', 'mommy', 'son', 'daughter', 'brother', 'sister', \n",
    "                         'grandchild', 'grandson', 'granddaughter', 'grandfather', 'grandmother', \n",
    "                         'grampa', 'grandpa', 'grandma', 'niece', 'nephew', 'uncle', 'aunt', 'cousin'\n",
    "                        'brother-in-law', 'sister-in-law', 'husband', 'wife']\n",
    "    me_list = ['i', 'my']\n",
    "    \n",
    "    grammar = r\"\"\"\n",
    "                PP: {<PRON><VERB><DET><ADJ>?<NOUN>}\n",
    "                NP: {<DET><ADJ>?<NOUN><PROPN>*}            \n",
    "                REL: {<PP>|<NP>}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition\n",
    "choose one of the two below (default=Flair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. spaCy NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "entities = []\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == 'PER':\n",
    "        entities.append(ent.text.lower())\n",
    "\n",
    "for token in doc:\n",
    "    if token.text.lower() in me_list:\n",
    "        entities.append(token.text.lower())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Flair NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "#nltk.download('wordnet')\n",
    "#lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# PER-PER entities\n",
    "def extract_per_to_per_entities(raw_sentence):\n",
    "    entities = []\n",
    "    \n",
    "    clean_sentence = re.sub('\\W+', ' ', raw_sentence) # remove non-word characters\n",
    "    sentence = Sentence(clean_sentence)\n",
    "    tagger = SequenceTagger.load(flair_ner_tagger_lang)\n",
    "    tagger.predict(sentence) # run NER over sentence\n",
    "    \n",
    "    # NER spans\n",
    "    for entity in sentence.get_spans('ner'):\n",
    "        print('Extracting entities...')\n",
    "        print(f'Entity: {entity}')\n",
    "\n",
    "        if entity.tag == 'PER':\n",
    "            if len(entity.tokens) > 1:  # if it is a multi word entity, replace blanks with underscores \n",
    "                entities.append(str(entity.text.lower()).replace(' ', '_'))\n",
    "            else:\n",
    "                entities.append(entity.text.lower())\n",
    "    \n",
    "    # check for personal pronoun in sentence\n",
    "    for token in sentence:\n",
    "        lemmatized_entity = lemmatizer.lemmatize(token.text.lower())\n",
    "        \n",
    "        if token.text.lower() in me_list:\n",
    "            entities.append(token.text.lower())\n",
    "                \n",
    "    # check for me or relationship\n",
    "    # Lemmatization\n",
    "    #if len(entities) == 0:\n",
    "    #    for token in sentence:\n",
    "    #        lemmatized_entity = lemmatizer.lemmatize(token.text.lower())\n",
    "\n",
    "    #        if token.text.lower() in me_list or lemmatized_entity in relationship_list:\n",
    "    #            entities.append(token.text.lower())\n",
    "\n",
    "    # NER tag for each token\n",
    "    #for token in sentence:\n",
    "    #    ner_tag = token.get_tag('ner')\n",
    "    #    print(f'{token}, {ner_tag}')\n",
    "\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build undirected graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_undirected_graph(sentence, plot=False):\n",
    "    doc = nlp(sentence)\n",
    "    edges = []\n",
    "    for token in doc:\n",
    "        for child in token.children:\n",
    "            edges.append((f'{token.lower_}',\n",
    "                          f'{child.lower_}'))\n",
    "    graph = nx.Graph(edges)\n",
    "    if plot:\n",
    "        plot_graph(graph)\n",
    "        \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(graph):\n",
    "    # nx.draw_networkx(graph, node_size=100, ode_color=range(len(graph)))\n",
    "    pos = nx.spring_layout(graph)  # positions for all nodes\n",
    "    # nodes\n",
    "    nx.draw_networkx_nodes(graph, pos, node_size=200)\n",
    "    # edges\n",
    "    nx.draw_networkx_edges(graph, pos, width=1)\n",
    "    # labels\n",
    "    nx.draw_networkx_labels(graph, pos, font_size=12, font_family='sans-serif')\n",
    "\n",
    "    plt.axis('off')  # disable axis\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shortest Dependency Path\n",
    "Find shortest dependency path between every found two entities in a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_dict = {}\n",
    "\n",
    "def search_shortest_dep_path(entities, sentence):\n",
    "    print(f'Searching shortest path between entities: {entities}')\n",
    "    graph = build_undirected_graph(sentence, plot=True)\n",
    "\n",
    "    for i, first_entity in enumerate(entities):\n",
    "        first_entity = first_entity.split('_')[0]  # use only first name of multi-word entities\n",
    "\n",
    "        for j in range(len(entities)):  # bidirectional relations\n",
    "        #for j in range(i+1, len(entities)):  # unidirectional relations\n",
    "            second_entity = entities[j]\n",
    "            second_entity = second_entity.split('_')[0]  # use only first name of multi-word entities\n",
    "            print(first_entity, second_entity)\n",
    "            \n",
    "            if not i == j and second_entity not in me_list:        \n",
    "                try:\n",
    "                    shortest_path = nx.shortest_path(graph, source=first_entity, target=second_entity)\n",
    "                    key = first_entity + '-' + second_entity\n",
    "                    #path_dict[key] = shortest_path  # include entities in sp\n",
    "                    path_dict[key] = shortest_path[1:-1]  # exclude entities in sp\n",
    "                except NodeNotFound as err:\n",
    "                    logging.warning(f'Node not found: {err}')\n",
    "                except NetworkXNoPath as err:\n",
    "                    logging.warning(f'No path found: {err}')\n",
    "    #else:\n",
    "    #    print('No persons found in sentence')\n",
    "    \n",
    "    return path_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexical analysis (based on ReVerb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 'daughter')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def search_rel_type(sentence):\n",
    "    for token in word_tokenize(sentence):\n",
    "        if token.lower() in relationship_list:\n",
    "            return token.lower()\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def pos_tag_sentence(sentence):\n",
    "    sentence = re.sub('\\W+', ' ', sentence)\n",
    "    doc = nlp(sentence)\n",
    "\n",
    "    pos_tagged_sentence = []\n",
    "    for token in doc:\n",
    "        pos_tuple = (token.text, token.pos_)\n",
    "        pos_tagged_sentence.append(pos_tuple)\n",
    "\n",
    "    return pos_tagged_sentence\n",
    "\n",
    "\n",
    "def chunk_sentence(pos_tagged_sentence):\n",
    "    cp = nltk.RegexpParser(grammar)\n",
    "    result = cp.parse(pos_tagged_sentence)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def extract_rel(sentence):\n",
    "    me = None\n",
    "\n",
    "    relative = search_rel_type(sentence)\n",
    "    if relative:\n",
    "        chunk_tree = chunk_sentence(pos_tag_sentence(sentence))\n",
    "\n",
    "        for i, sub_tree in enumerate(chunk_tree):\n",
    "            if type(sub_tree) is nltk.tree.Tree and sub_tree.label() == 'REL':\n",
    "                me = sub_tree[0][0][0]\n",
    "\n",
    "    return me, relative\n",
    "\n",
    "\n",
    "extract_rel('My daughter lives in Berlin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction relations\n",
    "* if PER-PER in sentence, use shortest dependency path to extract the features in between\n",
    "* if not PER-PER in senctence, find description of a user related person through lexical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##> Processing sentence: \"My daughter Lisa is moving to London next month.\"\n",
      "Extracting entities...\n",
      "Entity: PER-span [3]: \"Lisa\"\n",
      "Extracting entities...\n",
      "Entity: LOC-span [7]: \"London\"\n",
      "lemmatized: my\n",
      "lemmatized: daughter\n",
      "lemmatized: lisa\n",
      "lemmatized: is\n",
      "lemmatized: moving\n",
      "lemmatized: to\n",
      "lemmatized: london\n",
      "lemmatized: next\n",
      "lemmatized: month\n",
      "Entities found: ['lisa', 'my']\n",
      "Searching shortest path between entities: ['lisa', 'my']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python\\lib\\site-packages\\networkx\\drawing\\nx_pylab.py:611: MatplotlibDeprecationWarning: isinstance(..., numbers.Number)\n",
      "  if cb.is_numlike(alpha):\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lisa lisa\n",
      "lisa my\n",
      "my lisa\n",
      "my my\n",
      "Paths: {'my-lindsey': ['sister'], 'my-lisa': ['daughter']}\n"
     ]
    }
   ],
   "source": [
    "for sentence in sent_tokenize(text):\n",
    "    print(f'##> Processing sentence: \"{sentence}\"')\n",
    "    entities = extract_per_to_per_entities(sentence)\n",
    "    \n",
    "    if entities:\n",
    "        print(f'Entities found: {entities}')\n",
    "        paths = search_shortest_dep_path(entities, sentence)\n",
    "        print(f'Paths: {paths}')\n",
    "    else:\n",
    "        me_rels = extract_rel(sentence)\n",
    "        print(me_rels)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['m1', 'm2', 'm1_pos', 'm2_pos', 'before_m1', 'after_m2', 'between_words', \n",
    "                   'short_path', 'm1_head', 'm2_head']\n",
    "\n",
    "features = pd.DataFrame(columns=feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homer und sein sohn peter gehen mit milhouse ins kino \n",
      "ich gehe mit bart laufen \n",
      "meine enkelin lisa und mein enkel peter fliegen morgen nach london \n",
      "ned flanders ist der vater von rod und todd \n",
      "homer fährt mit seiner tochter lisa zum see \n"
     ]
    }
   ],
   "source": [
    "features_list = []  # for TF-IDF vectorization\n",
    "#ners = []\n",
    "\n",
    "# check for named entity 'PER' or 'PME' in each sentence\n",
    "#for ner_tuple in ner_tuples:\n",
    "#    if 'I-PER' in ner_tuple:\n",
    "#        ners.append(ner_tuple)\n",
    "#    elif ner_tuple[0].lower() in me_list:\n",
    "#        ners.append((ner_tuple[0], 'PME'))\n",
    "#    elif ner_tuple[0].lower() in relationship_list:\n",
    "#        ners.append((ner_tuple[0], 'SOC'))\n",
    "\n",
    "for sentence in sent_tokenize(text):\n",
    "    sentence = re.sub(r'\\W+', ' ', sentence.lower()) # remove non-word characters\n",
    "    print(sentence)\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    for key, value in path_dict.items():\n",
    "        # extract entities\n",
    "        m1 = key.split('-')[0]\n",
    "        m2 = key.split('-')[1]\n",
    "\n",
    "        short_path = value\n",
    "\n",
    "        # POS tagging and head\n",
    "        for token in doc:\n",
    "            if token.text.lower() == m1:\n",
    "                m1_pos_tag = token.pos_\n",
    "                m1_head = token.head.text\n",
    "                #m1_children = [child for child in token.children]\n",
    "            elif token.text.lower() == m2:\n",
    "                m2_pos_tag = token.pos_\n",
    "                m2_head = token.head.text\n",
    "                #m2_children = [child for child in token.children]\n",
    "\n",
    "        # Dependecy parsing\n",
    "        #dep_path = []\n",
    "        #for chunk in doc.noun_chunks:\n",
    "        #    if chunk.root.text.lower() == m1 or chunk.root.text.lower() == m2:\n",
    "        #        dep_path.append([chunk.root.text, chunk.root.dep_, chunk.root.head.text])  \n",
    "\n",
    "        # Between words\n",
    "        start_position_m1 = sentence.find(m1)\n",
    "        start_position_m2 = sentence.find(m2)\n",
    "\n",
    "        # verify if the words were found in the sentence\n",
    "        if not start_position_m1 == -1 and not start_position_m2 == -1:\n",
    "            start_position_between = start_position_m1 + len(m1) + 1\n",
    "            end_position_between = start_position_m2\n",
    "\n",
    "            between = sentence[start_position_between:end_position_between]\n",
    "            between_words = []\n",
    "            for word in word_tokenize(between):\n",
    "                between_words.append(word)\n",
    "\n",
    "            beforeM1 = sentence[:start_position_m1 - 1]\n",
    "            afterM2 = sentence[start_position_m2 + len(m2):]\n",
    "\n",
    "            beforeM1_list = word_tokenize(beforeM1)\n",
    "            afterM2_list = word_tokenize(afterM2)\n",
    "\n",
    "            data = {'m1': m1, 'm2': m2, 'm1_pos': m1_pos_tag, 'm2_pos': m2_pos_tag,\n",
    "                    'before_m1': beforeM1_list, 'after_m2': afterM2_list,\n",
    "                    'between_words': between_words, 'short_path': short_path,\n",
    "                     'm1_head': m1_head, 'm2_head': m2_head}\n",
    "\n",
    "            training_example = pd.Series(data, index=feature_columns)\n",
    "            features = features.append(training_example, ignore_index=True)\n",
    "            #context = [beforeM1, between, afterM2]\n",
    "            #features_list.append(context)\n",
    "\n",
    "#features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m1</th>\n",
       "      <th>m2</th>\n",
       "      <th>m1_pos</th>\n",
       "      <th>m2_pos</th>\n",
       "      <th>before_m1</th>\n",
       "      <th>after_m2</th>\n",
       "      <th>between_words</th>\n",
       "      <th>short_path</th>\n",
       "      <th>m1_head</th>\n",
       "      <th>m2_head</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>homer</td>\n",
       "      <td>peter</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>[homer, und, sein, sohn, peter, gehen, mit, mi...</td>\n",
       "      <td>[gehen, mit, milhouse, ins, kino]</td>\n",
       "      <td>[und, sein, sohn]</td>\n",
       "      <td>[und, sohn]</td>\n",
       "      <td>gehen</td>\n",
       "      <td>gehen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>homer</td>\n",
       "      <td>milhouse</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>[homer, und, sein, sohn, peter, gehen, mit, mi...</td>\n",
       "      <td>[ins, kino]</td>\n",
       "      <td>[und, sein, sohn, peter, gehen, mit]</td>\n",
       "      <td>[gehen, mit]</td>\n",
       "      <td>gehen</td>\n",
       "      <td>mit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>peter</td>\n",
       "      <td>milhouse</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>[homer, und, sein, sohn]</td>\n",
       "      <td>[ins, kino]</td>\n",
       "      <td>[gehen, mit]</td>\n",
       "      <td>[sohn, und, homer, gehen, mit]</td>\n",
       "      <td>gehen</td>\n",
       "      <td>mit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lisa</td>\n",
       "      <td>peter</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>[meine, enkelin]</td>\n",
       "      <td>[fliegen, morgen, nach, london]</td>\n",
       "      <td>[und, mein, enkel]</td>\n",
       "      <td>[und, enkel]</td>\n",
       "      <td>meine</td>\n",
       "      <td>und</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ned</td>\n",
       "      <td>rod</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>[ned, flanders, ist, der, vater, von, rod, und...</td>\n",
       "      <td>[und, todd]</td>\n",
       "      <td>[flanders, ist, der, vater, von]</td>\n",
       "      <td>[flanders, ist, vater, von]</td>\n",
       "      <td>flanders</td>\n",
       "      <td>von</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ned</td>\n",
       "      <td>todd</td>\n",
       "      <td>X</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>[ned, flanders, ist, der, vater, von, rod, und...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[flanders, ist, der, vater, von, rod, und]</td>\n",
       "      <td>[flanders, ist, vater, von, rod, und]</td>\n",
       "      <td>flanders</td>\n",
       "      <td>und</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rod</td>\n",
       "      <td>todd</td>\n",
       "      <td>X</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>[ned, flanders, ist, der, vater, von]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[und]</td>\n",
       "      <td>[und]</td>\n",
       "      <td>von</td>\n",
       "      <td>und</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>homer</td>\n",
       "      <td>lisa</td>\n",
       "      <td>ADV</td>\n",
       "      <td>X</td>\n",
       "      <td>[homer, fährt, mit, seiner, tochter, lisa, zum...</td>\n",
       "      <td>[zum, see]</td>\n",
       "      <td>[fährt, mit, seiner, tochter]</td>\n",
       "      <td>[fährt, mit, tochter]</td>\n",
       "      <td>fährt</td>\n",
       "      <td>mit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      m1        m2 m1_pos m2_pos  \\\n",
       "0  homer     peter    ADJ    ADJ   \n",
       "1  homer  milhouse    ADJ    ADJ   \n",
       "2  peter  milhouse    ADJ    ADJ   \n",
       "3   lisa     peter   VERB    ADJ   \n",
       "4    ned       rod      X      X   \n",
       "5    ned      todd      X    ADJ   \n",
       "6    rod      todd      X    ADJ   \n",
       "7  homer      lisa    ADV      X   \n",
       "\n",
       "                                           before_m1  \\\n",
       "0  [homer, und, sein, sohn, peter, gehen, mit, mi...   \n",
       "1  [homer, und, sein, sohn, peter, gehen, mit, mi...   \n",
       "2                           [homer, und, sein, sohn]   \n",
       "3                                   [meine, enkelin]   \n",
       "4  [ned, flanders, ist, der, vater, von, rod, und...   \n",
       "5  [ned, flanders, ist, der, vater, von, rod, und...   \n",
       "6              [ned, flanders, ist, der, vater, von]   \n",
       "7  [homer, fährt, mit, seiner, tochter, lisa, zum...   \n",
       "\n",
       "                            after_m2  \\\n",
       "0  [gehen, mit, milhouse, ins, kino]   \n",
       "1                        [ins, kino]   \n",
       "2                        [ins, kino]   \n",
       "3    [fliegen, morgen, nach, london]   \n",
       "4                        [und, todd]   \n",
       "5                                 []   \n",
       "6                                 []   \n",
       "7                         [zum, see]   \n",
       "\n",
       "                                between_words  \\\n",
       "0                           [und, sein, sohn]   \n",
       "1        [und, sein, sohn, peter, gehen, mit]   \n",
       "2                                [gehen, mit]   \n",
       "3                          [und, mein, enkel]   \n",
       "4            [flanders, ist, der, vater, von]   \n",
       "5  [flanders, ist, der, vater, von, rod, und]   \n",
       "6                                       [und]   \n",
       "7               [fährt, mit, seiner, tochter]   \n",
       "\n",
       "                              short_path   m1_head m2_head  \n",
       "0                            [und, sohn]     gehen   gehen  \n",
       "1                           [gehen, mit]     gehen     mit  \n",
       "2         [sohn, und, homer, gehen, mit]     gehen     mit  \n",
       "3                           [und, enkel]     meine     und  \n",
       "4            [flanders, ist, vater, von]  flanders     von  \n",
       "5  [flanders, ist, vater, von, rod, und]  flanders     und  \n",
       "6                                  [und]       von     und  \n",
       "7                  [fährt, mit, tochter]     fährt     mit  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vector_feature_columns = ['m1', 'm2', 'short_path_vector', 'm1_head', 'm2_head']\n",
    "vector_features = pd.DataFrame(columns=vector_feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embeddings of the words inside the shortest path and sum them into a single vector\n",
    "* Two Representations: GermanWordEmbeddings and Flair Word Embeddings\n",
    "Choose one of the two below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. GermanWordEmbeddings https://github.com/devmount/GermanWordEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\program files\\python\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"word 'homer' not in vocabulary\"\n",
      "\"word 'mit' not in vocabulary\"\n",
      "\"word 'milhouse' not in vocabulary\"\n",
      "\"word 'flanders' not in vocabulary\"\n",
      "\"word 'ist' not in vocabulary\"\n",
      "\"word 'von' not in vocabulary\"\n",
      "\"word 'flanders' not in vocabulary\"\n",
      "\"word 'ist' not in vocabulary\"\n",
      "\"word 'von' not in vocabulary\"\n",
      "\"word 'und' not in vocabulary\"\n",
      "\"word 'todd' not in vocabulary\"\n",
      "\"word 'und' not in vocabulary\"\n",
      "\"word 'todd' not in vocabulary\"\n",
      "\"word 'homer' not in vocabulary\"\n",
      "\"word 'fährt' not in vocabulary\"\n",
      "\"word 'mit' not in vocabulary\"\n",
      "\"word 'tochter' not in vocabulary\"\n",
      "\"word 'lisa' not in vocabulary\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m1</th>\n",
       "      <th>m2</th>\n",
       "      <th>short_path_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>homer</td>\n",
       "      <td>milhouse</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ned</td>\n",
       "      <td>rod</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ned</td>\n",
       "      <td>todd</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rod</td>\n",
       "      <td>todd</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>homer</td>\n",
       "      <td>lisa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      m1        m2 short_path_vector\n",
       "0  homer  milhouse               NaN\n",
       "1    ned       rod               NaN\n",
       "2    ned      todd               NaN\n",
       "3    rod      todd               NaN\n",
       "4  homer      lisa               NaN"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ger_model = KeyedVectors.load_word2vec_format('../models/german.model', binary=True)\n",
    "\n",
    "embedding_vectors = []\n",
    "# get vector length\n",
    "vector_len = len(ger_model.wv['hallo'])\n",
    "\n",
    "for row in features.iterrows():\n",
    "    m1 = row[1]['m1']\n",
    "    m2 = row[1]['m2']\n",
    "    short_path = row[1]['short_path']\n",
    "    \n",
    "    # get the word embedding representation for each word in the shortest path\n",
    "    #row_embeddings = np.empty(len(short_path))\n",
    "    row_embeddings = []\n",
    "    \n",
    "    for word in short_path:\n",
    "        try:\n",
    "            row_embeddings.append(ger_model.wv[word])\n",
    "        except KeyError as err:\n",
    "            print(err)\n",
    "            row_embeddings.append(np.zeros(vector_len))\n",
    "    \n",
    "    #print(sum(row_embeddings))\n",
    "    embedding_vectors.append(sum(row_embeddings))\n",
    "    vector_data = {'m1': m1, 'm2': m2, 'short_path_embedding_vector': sum(row_embeddings)}\n",
    "    training_example = pd.Series(vector_data, index=vector_feature_columns)\n",
    "    vector_features = vector_features.append(training_example, ignore_index=True)\n",
    "\n",
    "# summarize vectors    \n",
    "#row_embeddings.sum()\n",
    "vector_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Flair Word Embeddings  https://github.com/zalandoresearch/flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence, Token\n",
    "from flair.embeddings import WordEmbeddings\n",
    "\n",
    "flair_embeddings = {}\n",
    "for sentence in sent_tokenize(text):\n",
    "    sentence = re.sub(r'\\W', ' ', sentence)\n",
    "    sentence = re.sub(r'\\s{2,}', ' ', sentence)    \n",
    "    \n",
    "    sentence = Sentence(sentence.lower())\n",
    "    glove_embedding = WordEmbeddings('de')\n",
    "    #glove_embedding = WordEmbeddings('de-crawl')\n",
    "    glove_embedding.embed(sentence)\n",
    "    \n",
    "    for token in sentence:\n",
    "        flair_embeddings[token.text] = token.embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop word found: und\n",
      "stop word found: mit\n",
      "stop word found: und\n",
      "stop word found: mit\n",
      "stop word found: und\n",
      "stop word found: ist\n",
      "stop word found: von\n",
      "stop word found: ist\n",
      "stop word found: von\n",
      "stop word found: und\n",
      "stop word found: und\n",
      "stop word found: mit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['homer-peter',\n",
       " 'homer-milhouse',\n",
       " 'peter-milhouse',\n",
       " 'lisa-peter',\n",
       " 'ned-rod',\n",
       " 'ned-todd',\n",
       " 'homer-lisa']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flair_embedding_vectors = []\n",
    "labels = []\n",
    "for row in features.iterrows():\n",
    "    m1 = row[1]['m1']\n",
    "    m2 = row[1]['m2']\n",
    "    short_path = row[1]['short_path']\n",
    "    m1_head = row[1]['m1_head']\n",
    "    m2_hed = row[1]['m2_head']\n",
    "    \n",
    "    # get the word embedding for each word in the shortest path\n",
    "    row_embeddings = []\n",
    "    \n",
    "    for word in short_path:\n",
    "        if word not in stop_words:  # exclude stop words\n",
    "            try:\n",
    "                #row_embeddings.append(flair_embeddings[word])\n",
    "                # weight embedding higher if it contains a relation\n",
    "                if word.lower() in relationship_list:\n",
    "                    row_embeddings.append(flair_embeddings[word]*1.8)\n",
    "                else:\n",
    "                    row_embeddings.append(flair_embeddings[word])\n",
    "            except KeyError as err:\n",
    "                print(err)\n",
    "                row_embeddings.append(np.zeros(vector_len))\n",
    "        else:\n",
    "            print(f'exclude stop word: {word}')\n",
    "    \n",
    "    # append word embeddings for head words\n",
    "    \"\"\"\n",
    "    if m1_head:\n",
    "        try:\n",
    "            row_embeddings.append(flair_embeddings[m1_head])\n",
    "        except KeyError as err:\n",
    "            print(err)\n",
    "    if m2_head:\n",
    "        try:\n",
    "            row_embeddings.append(flair_embeddings[m2_head])\n",
    "        except KeyError as err:\n",
    "            print(err)\n",
    "    \"\"\"\n",
    "    \n",
    "    if row_embeddings:\n",
    "        flair_embedding_vectors.append(sum(row_embeddings))\n",
    "        labels.append(m1+'-'+m2)\n",
    "        #vector_data = {'m1': m1, 'm2': m2, 'short_path_embedding_vector': sum(row_embeddings)}\n",
    "        #training_example = pd.Series(vector_data, index=vector_feature_columns)\n",
    "        #vector_features = vector_features.append(training_example, ignore_index=True)\n",
    "\n",
    "#vector_features\n",
    "#flair_embedding_vectors\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create tuples of the word vector representations for plotting purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tuples = ()\n",
    "for vector in flair_embedding_vectors:\n",
    "    if not tuples:\n",
    "        tuples = (vector, )\n",
    "    else:\n",
    "        tuples = tuples + (vector, )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot summarized word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 7 is out of bounds for axis 0 with size 7",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-144-cb0f24fc9170>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 7 is out of bounds for axis 0 with size 7"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = np.vstack(tuples)\n",
    "pca = PCA(n_components=2)\n",
    "result = pca.fit_transform(X)\n",
    "\n",
    "plt.scatter(result[:, 0], result[:, 1])\n",
    "words = list(path_dict.keys())\n",
    "for i, word in enumerate(words):\n",
    "    plt.annotate(word, xy=(result[i, 0], result[i, 1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dendrogram for choosing the right number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-130-423fdc35cb0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mdistance_sort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'descending'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             show_leaf_counts=True)\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python\\lib\\site-packages\\scipy\\cluster\\hierarchy.py\u001b[0m in \u001b[0;36mdendrogram\u001b[1;34m(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color)\u001b[0m\n\u001b[0;32m   2494\u001b[0m         \u001b[0mcontraction_marks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcontraction_marks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2495\u001b[0m         \u001b[0mlink_color_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlink_color_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2496\u001b[1;33m         above_threshold_color=above_threshold_color)\n\u001b[0m\u001b[0;32m   2497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2498\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_plot\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python\\lib\\site-packages\\scipy\\cluster\\hierarchy.py\u001b[0m in \u001b[0;36m_dendrogram_calculate_info\u001b[1;34m(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, i, iv, ivl, n, icoord_list, dcoord_list, lvs, mhr, current_color, color_list, currently_below_threshold, leaf_label_func, level, contraction_marks, link_color_func, above_threshold_color)\u001b[0m\n\u001b[0;32m   2747\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontraction_marks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcontraction_marks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2748\u001b[0m             \u001b[0mlink_color_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlink_color_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2749\u001b[1;33m             above_threshold_color=above_threshold_color)\n\u001b[0m\u001b[0;32m   2750\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2751\u001b[0m     \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python\\lib\\site-packages\\scipy\\cluster\\hierarchy.py\u001b[0m in \u001b[0;36m_dendrogram_calculate_info\u001b[1;34m(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, i, iv, ivl, n, icoord_list, dcoord_list, lvs, mhr, current_color, color_list, currently_below_threshold, leaf_label_func, level, contraction_marks, link_color_func, above_threshold_color)\u001b[0m\n\u001b[0;32m   2747\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontraction_marks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcontraction_marks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2748\u001b[0m             \u001b[0mlink_color_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlink_color_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2749\u001b[1;33m             above_threshold_color=above_threshold_color)\n\u001b[0m\u001b[0;32m   2750\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2751\u001b[0m     \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python\\lib\\site-packages\\scipy\\cluster\\hierarchy.py\u001b[0m in \u001b[0;36m_dendrogram_calculate_info\u001b[1;34m(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, i, iv, ivl, n, icoord_list, dcoord_list, lvs, mhr, current_color, color_list, currently_below_threshold, leaf_label_func, level, contraction_marks, link_color_func, above_threshold_color)\u001b[0m\n\u001b[0;32m   2659\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2660\u001b[0m         _append_singleton_leaf_node(Z, p, n, level, lvs, ivl,\n\u001b[1;32m-> 2661\u001b[1;33m                                     leaf_label_func, i, labels)\n\u001b[0m\u001b[0;32m   2662\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0miv\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m5.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2663\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python\\lib\\site-packages\\scipy\\cluster\\hierarchy.py\u001b[0m in \u001b[0;36m_append_singleton_leaf_node\u001b[1;34m(Z, p, n, level, lvs, ivl, leaf_label_func, i, labels)\u001b[0m\n\u001b[0;32m   2529\u001b[0m             \u001b[1;31m# for the leaf nodes, use it.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2530\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2531\u001b[1;33m                 \u001b[0mivl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2532\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2533\u001b[0m                 \u001b[1;31m# Otherwise, use the id as the label for the leaf.x\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage  \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "linked = linkage(X, 'single')\n",
    "\n",
    "#labelList = range(1, 11)\n",
    "\n",
    "plt.figure(figsize=(10, 7))  \n",
    "dendrogram(linked,  \n",
    "            orientation='top',\n",
    "            labels=words,\n",
    "            distance_sort='descending',\n",
    "            show_leaf_counts=True)\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define number of clusters depending on the dendogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agglomerative Hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4, 5, 0, 2, 3, 1], dtype=int64)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "#labels = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
    "labels = words\n",
    "agglo_clustering = AgglomerativeClustering(linkage='ward', affinity='euclidean', n_clusters=n)\n",
    "agglo_clustering.fit(X, labels)\n",
    "\n",
    "agglo_clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1f64cc331d0>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[:,0],X[:,1], c=agglo_clustering.labels_, cmap='rainbow')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 2, 1, 0, 1, 1, 3, 0, 1, 1, 0, 0, 0, 2, 2, 0, 1, 3, 3,\n",
       "       2, 1, 0, 2, 2, 1, 0, 0, 1, 3, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0, 2, 2,\n",
       "       3, 2, 2, 0, 0, 2, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 3, 2, 0, 2,\n",
       "       1, 1, 0, 0, 0, 2, 0, 3, 0, 1, 1, 1, 1, 2, 0, 0, 2, 2, 2, 0, 1, 3,\n",
       "       0, 2, 2, 2, 2, 0, 1, 2, 3, 1, 0, 0, 2, 1, 2, 1, 3, 1, 2, 0, 2, 2,\n",
       "       2, 3, 1, 0, 3, 2, 1, 2, 0, 1, 2, 2, 1, 3, 2, 3, 2, 2, 1, 2, 2, 1,\n",
       "       2, 1, 2, 1, 2, 3, 1, 2, 0, 2, 2, 3, 0, 0, 1, 1, 0, 1, 1, 2, 2, 1,\n",
       "       2, 2, 0, 3, 3, 1, 0, 1, 2, 1, 0, 1, 0, 2, 0, 2, 0, 0, 2, 2, 1, 1,\n",
       "       1, 0, 1, 0, 2, 1, 2, 0, 3, 1, 0, 2, 2, 2, 1, 1, 2, 2, 3, 2, 0, 1,\n",
       "       0, 2, 2, 2, 3, 2, 2, 3, 2, 0, 1, 2, 1, 2, 1, 1, 0, 3, 0, 0, 1, 1,\n",
       "       0, 2, 2, 2, 0, 1, 1, 2, 1, 3, 2, 2, 2, 2, 0, 0, 0, 0, 1, 2, 2, 2,\n",
       "       1, 2, 2, 2, 0, 2, 0, 3, 2, 1, 0, 2, 2, 0, 3, 2, 2, 2, 2, 2, 2, 3,\n",
       "       2, 2, 2, 1, 2, 0, 2, 1, 3, 0, 1, 0, 1, 0, 0, 3, 1, 3, 1, 1, 3, 0,\n",
       "       0, 0, 0, 2, 2, 2, 1, 3, 0, 0, 2, 2, 1, 3], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agglo_clustering.fit_predict(np.vstack(tuples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
